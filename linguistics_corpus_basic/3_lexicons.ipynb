{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3: Lexicons\n",
    "\n",
    "* Word \"Lists\" (Sets)\n",
    "* Simple dictionary lexicons\n",
    "* Complex lexicons\n",
    "* Lexicons in NLTK\n",
    "* Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word \"Lists\" (Sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The simpliest lexicon is just a list of words that have something in common. For example:\n",
    "\n",
    "* Pronouns (\"he\",\"she\", \"I\", ...)\n",
    "* Negative words (\"terrible\",\"jerk\",\"foolishly\",...)\n",
    "* A list of all family relations (\"father\", \"sister\",...)\n",
    "* The vocabulary of the Brown corpus\n",
    "\n",
    "Typically, one builds a lexicon so that one can identify instances of this word class in some corpus\n",
    "\n",
    "Rule #1: Don't use lists for lexicons. Use [sets](https://docs.python.org/3/library/stdtypes.html#set-types-set-frozenset)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brown', 'dog', 'fox', 'jumped', 'lazy', 'over', 'quick', 'the'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words = [\"the\",\"quick\",\"brown\", \"fox\",\"jumped\", \"over\",\"the\",\"lazy\",\"dog\"]\n",
    "\n",
    "lexicon = set(some_words)\n",
    "lexicon\n",
    "# lexicon[3]  if you run this, you will get an error saying \n",
    "# TypeError: 'set' object is not subscriptable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two big reasons to use sets for lexicons:\n",
    "\n",
    "* Elements are unique, which is exactly what you need for lexicons\n",
    "* As we know, checking for membership (*in*) is much faster, $O(1)$ vs $O(n)$. This especially matters when the lexicon is big."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are a few ways to create sets. \n",
    "- If you are starting totally from scratch, you have to use the build-in *set()* function\n",
    "    - curly brackets alone refer to dicts, not sets! \n",
    "- If you are starting with a (small) fixed set of existing items you can declare using curly brackets instead of converting a list. \n",
    "- There are also set comprehensions, also using curly brackets!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "seasons = {\"spring\", \"summer\", \"fall\"}\n",
    "months = {}\n",
    "days = {n for n in range(31)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fall', 'spring', 'summer', 'winter'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons.add(\"winter\")\n",
    "seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31}\n"
     ]
    }
   ],
   "source": [
    "days.add(31)\n",
    "print(days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'January'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = set()\n",
    "months.add(\"January\")\n",
    "months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is worth memorizing the basic set methods for adding and removing items, including `add`, `update`, and `discard`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "planets = {\"Mars\",\"Venus\", \"Mercury\"}\n",
    "more_planets = [\"Jupiter\",\"Neptune,\",\"Uranus\", \"Pluto\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Earth', 'Mars', 'Mercury', 'Venus'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets.add(\"Earth\")\n",
    "planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Earth', 'Jupiter', 'Mars', 'Mercury', 'Neptune,', 'Pluto', 'Uranus', 'Venus'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets.update(more_planets)\n",
    "planets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Earth', 'Jupiter', 'Mars', 'Mercury', 'Neptune,', 'Uranus', 'Venus'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "planets.discard(\"Pluto\")\n",
    "planets\n",
    "planets.discard(\"Ceres\")\n",
    "planets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sets are great for quickly finding intersections using `&` and differences using `-`. These are WAY faster than alternatives involving looping. Let's find words only in both the Brown and Treebank, and words that appear in only one or the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brown vocab:  56057\n",
      "treebank vocab:  12408\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown, treebank\n",
    "\n",
    "brown_vocab = set(brown.words())\n",
    "print('brown vocab: ', len(brown_vocab))\n",
    "treebank_vocab = set(treebank.words())\n",
    "print('treebank vocab: ', len(treebank_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47510"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown_vocab - treebank_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3861"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(treebank_vocab - brown_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8547"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(treebank_vocab & brown_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You might sometimes want to intersect a set with something that isn't a set (like a list, or even a string). If so, and it doesn't make sense to convert the other to a set, you can use set methods such as `intersection` instead of operators (which only work when both elements are sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowels = {'a','e','i','o','u','y'}\n",
    "word1 = \"rstln\"\n",
    "word2 = \"rstlne\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(vowels & word1) \n",
    "# If you run this, it will throw an error saying \n",
    "# TypeError: unsupported operand type(s) for &: 'set' and 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowels.intersection(word1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowels.intersection(word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word1.intersection(word2)\n",
    "# This is also wrong because 'str' object has no attribute 'intersection'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some set drawbacks:\n",
    "\n",
    "* No order, no guarantee that order will be perserved when the set changes\n",
    "* Can't add mutuable objects like lists and dicts (use tuples!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feb', 'Mar', 'Jan']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "months = [\"Jan\", \"Feb\", \"Mar\"]\n",
    "\n",
    "list(set(months))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple dictionary lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Most common lexical need in computational linguistics: word counts\n",
    "\n",
    "Easy way to build a dictionary of counts when you've got a list (or other iterable) of words: [Counters](https://docs.python.org/3/library/collections.html#collections.Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(brown.words())\n",
    "counts[\"brown\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62713"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can `update` counters to add more items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66758"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.update(treebank.words())\n",
    "counts[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But sometimes not practical because what you are counting isn't an iterable or you want to do some operation before counting. A normal Python dict is fine, but each value needs to be initialized to zero. One solution: the [get](https://docs.python.org/3/library/stdtypes.html#dict.get) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69971"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = {}\n",
    "for word in brown.words():\n",
    "    word = word.lower()\n",
    "    counts[word] = counts.get(word, 0) + 1\n",
    "     \n",
    "    \n",
    "counts[\"the\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A quick exercise: let's count the first words of sentences in the Brown corpus using `get`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "789\n"
     ]
    }
   ],
   "source": [
    "first_word_count = {}\n",
    "for sent in brown.sents():\n",
    "    word = sent[0]\n",
    "    first_word_count[word] = first_word_count.get(word, 0) + 1\n",
    "    \n",
    "print(first_word_count[\"And\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yet another solution to the initialization problem for counting (and other situations) is the [defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict). When you initialize a defaultdict for integers, the default value is zero, no need to do anything but add! Defaultdicts also work for lists, sets, and dicts (creating an empty instance as soon as you try to access it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62713\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.corpus import brown\n",
    "\n",
    "counts = defaultdict(int)\n",
    "\n",
    "for word in brown.words():\n",
    "    counts[word] = counts[word] + 1\n",
    "    \n",
    "print(counts[\"the\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another very common need: assign a index (an integer) to each word, for looking up in data structures like matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10449"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_dict = {}\n",
    "\n",
    "for word in counts:\n",
    "    index_dict[word] = len(index_dict)\n",
    "    \n",
    "index_dict[\"index\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In these cases, you will often need a reversed index as well. The `items` method for dictionaries is useful if you are iterating over an existing dictionary and want to access both key and value at the same time. Let's build a reverse index dict in one line using a dictionary comprehension!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'index'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_dict = {value:key for key, value in index_dict.items()}\n",
    "rev_dict[10449]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Complex lexicons\n",
    "\n",
    "\n",
    "Sometimes lexicons are more complex and might be represented as multiple recursive Python datatypes. For example, instead of a single counts, you might have a list of word senses, which are actually dictionaries of properties (including part-of-speech and counts of that word sense in a corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mini_sense_lexicon = {\"bear\":[{\"POS\":\"noun\",\"animate\":True,\"count\":634,\"gloss\":\"A big furry animal\"},\n",
    "                              {\"POS\":\"verb\",\"transitive\":True,\"count\":294, \"past tense\":\"bore\", \"past participle\":\"borne\", \"gloss\":\"to endure\"}],\n",
    "                      \"slug\":[{\"POS\":\"noun\",\"animate\":True,\"count\":34, \"gloss\":\"A slimy animal\"},\n",
    "                              {\"POS\":\"verb\",\"transitive\":True,\"count\":3, \"gloss\": \"to hit\"}],\n",
    "                      \"back\":[{\"POS\":\"noun\",\"animate\":False,\"count\":12,\"gloss\":\"a body part\"},\n",
    "                              {\"POS\":\"noun\",\"animate\":False,\"count\":43, \"gloss\":\"the rear of a place\"},\n",
    "                              {\"POS\":\"verb\",\"transitive\":True,\"count\":5, \"gloss\":\"to support\"},\n",
    "                              {\"POS\":\"adverb\",\"count\":47,\"gloss\":\"in a returning fashion\"}],\n",
    "                      \"good\":[{\"POS\":\"noun\",\"animate\":False,\"count\":19,\"gloss\":\"a thing of value\"},\n",
    "                              {\"POS\":\"adjective\", \"count\":1293,\"gloss\":\"positive\"}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These can be tricky to navigate. Let's answer the following questions by accessing the information in data structure:\n",
    "\n",
    "How many senses does \"back\" have in this lexicon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mini_sense_lexicon[\"bear\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Does \"slug\" have an adjectival sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(features[\"POS\"] == \"adjective\" for features in mini_sense_lexicon[\"slug\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which words have a verb sense with an irregular past tense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear\n"
     ]
    }
   ],
   "source": [
    "for word in mini_sense_lexicon:\n",
    "    for feature_dict in mini_sense_lexicon[word]:\n",
    "        if (\"past tense\" in feature_dict):\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the gloss of the most common sense of \"back\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest:  47\n",
      "Gloss:  in a returning fashion\n"
     ]
    }
   ],
   "source": [
    "highest_val = 0\n",
    "gloss = \"\"\n",
    "for feature_dict in mini_sense_lexicon[\"back\"]:\n",
    "    if(feature_dict[\"count\"] > highest_val):\n",
    "        highest_val = feature_dict[\"count\"]\n",
    "        gloss = feature_dict[\"gloss\"]\n",
    "\n",
    "print(\"Highest: \", highest_val)\n",
    "print(\"Gloss: \", gloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## NLTK lexicons\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "NLTK has a lot of useful lexicons. Most are word lists. Note that they are listed under corpora and have the same interface; note that they need to be converted to sets if you want to use them for look up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Stopwords\n",
    "\n",
    "Lists of closed-class/function words in various languages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"english\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"french\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Swadesh\n",
    "\n",
    "words for 200 common concepts from large list of languages, used for historical linguistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import swadesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['be', 'bg', 'bs', 'ca', 'cs', 'cu', 'de', 'en', 'es', 'fr', 'hr', 'it', 'la', 'mk', 'nl', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'sr', 'sw', 'uk']\n"
     ]
    }
   ],
   "source": [
    "print(swadesh.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ich\n",
      "you (singular), thou du, Sie\n",
      "he er\n",
      "we wir\n",
      "you (plural) ihr, Sie\n",
      "they sie\n",
      "this dieses\n",
      "that jenes\n",
      "here hier\n",
      "there dort\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(swadesh.words(\"en\")[i], swadesh.words(\"de\")[i]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Names\n",
    "\n",
    "Lists of mostly English names, divided by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female.txt', 'male.txt']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zonnya',\n",
       " 'Zora',\n",
       " 'Zorah',\n",
       " 'Zorana',\n",
       " 'Zorina',\n",
       " 'Zorine',\n",
       " 'Zsa Zsa',\n",
       " 'Zsazsa',\n",
       " 'Zulema',\n",
       " 'Zuzana']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.words(\"female.txt\")[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Opinion Lexicon\n",
    "\n",
    "Positive and negative word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import opinion_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['negative-words.txt', 'positive-words.txt']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_lexicon.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opinion_lexicon.words('negative-words.txt')[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### CMU Pronouncing Dictionary\n",
    "\n",
    "* A list of pronunciations for each English word string\n",
    "* Pronunciations are a list of ARPAbet phones\n",
    "* ARPAbet phones are strings which are alphabetic except for numbers at the end of the vowels\n",
    "* The numbers indicate stress\n",
    "\n",
    "Let's look at a few entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import cmudict\n",
    "p_dict = cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DH', 'EH1', 'R']]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict[\"there\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['DH', 'EH1', 'R']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict[\"their\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['R', 'EH1', 'D'], ['R', 'IY1', 'D']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_dict[\"read\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's get some basic stats for this lexicon: total entries, average number of pronunciations per word, average number of phones per pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pro_count = 0\n",
    "pho_count = 0\n",
    "for pronuns in p_dict.values():\n",
    "    pro_count += len(pronuns)\n",
    "    for pronun in pronuns:\n",
    "        pho_count += len(pronun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123455"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0832854076384109"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_per_word = pro_count / len(p_dict)\n",
    "pro_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.3850542482633825"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pho_count / (len(p_dict) * pro_per_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Create a set of female names that appear in the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702\n",
      "5001\n"
     ]
    }
   ],
   "source": [
    "types = set(brown.words())\n",
    "female_names = set(names.words(\"female.txt\"))\n",
    "\n",
    "female_brown = types & female_names\n",
    "female_brown\n",
    "print(len(female_brown))\n",
    "print(len(female_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (Programmatically) create a set of the words from `mini_sense_lexicon` which have an animate noun sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bear', 'slug'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animates = set()\n",
    "for word in mini_sense_lexicon:\n",
    "    for feature_dict in mini_sense_lexicon[word]:\n",
    "        if (\"animate\" in feature_dict and feature_dict[\"animate\"]):\n",
    "            animates.add(word)\n",
    "            \n",
    "animates\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Count how often each English phone appears in CMU lexicon, striping off the stress markers at the end of vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'AH': 71410, 'EY': 13521, 'F': 13748, 'AO': 11290, 'R': 46046, 'T': 48549, 'UW': 9736, 'W': 8864, 'N': 60564, 'IH': 50093, 'P': 19715, 'L': 49479, 'AA': 24546, 'B': 21057, 'ER': 29027, 'G': 13553, 'K': 42502, 'S': 50427, 'EH': 27398, 'TH': 2902, 'M': 29347, 'D': 32389, 'V': 10742, 'Z': 27842, 'IY': 34504, 'AE': 21804, 'OW': 19047, 'NG': 9865, 'SH': 8700, 'HH': 9319, 'AW': 3408, 'AY': 11313, 'JH': 6404, 'Y': 5171, 'CH': 4960, 'ZH': 560, 'UH': 2273, 'DH': 576, 'OY': 1267})\n"
     ]
    }
   ],
   "source": [
    "phones = defaultdict(int)\n",
    "for word in p_dict:\n",
    "    for pron in p_dict[word]:\n",
    "        for phone in pron:\n",
    "            if not phone[-1].isdigit():\n",
    "                phones[phone] = phones[phone] + 1\n",
    "            else:\n",
    "                phones[phone[:-1]] = phones[phone[:-1]] + 1\n",
    "                \n",
    "print(phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
