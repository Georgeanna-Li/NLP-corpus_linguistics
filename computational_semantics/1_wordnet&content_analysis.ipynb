{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Lexical semantics\n",
    "\n",
    "* What do words mean?\n",
    "* WordNet\n",
    "* Word Sense Disambiguation\n",
    "* Content analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What do words mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Dictionary definitions?\n",
    "* Relationship to other words?\n",
    "* Lexical categories?\n",
    "* Linguistic context in which they appear?\n",
    "* Referents in the \"real world\"?\n",
    "* Effects in the mind of a listener?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "[WordNet](https://wordnet.princeton.edu/) is a lexical database that structures words primarily in terms of two key relationships: *synonymy* and *hypernomy*. Synonymy is when two words mean (approximately) the same thing, and WordNet represents synonymy by organizing words into groups of synonyms called *synsets*. Ironically, the synset, not the word, is the fundamental unit of WordNet.\n",
    "\n",
    "Let's start by looking at the size of (English) WordNet in terms of different parts of speech. We can get all the synsets for a POS using the `all_synsets` command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n",
      "82115\n",
      "[Synset('entity.n.01'), Synset('physical_entity.n.01'), Synset('abstraction.n.06'), Synset('thing.n.12'), Synset('object.n.01'), Synset('whole.n.02'), Synset('congener.n.03'), Synset('living_thing.n.01'), Synset('organism.n.01'), Synset('benthos.n.02')]\n",
      "v\n",
      "13767\n",
      "[Synset('breathe.v.01'), Synset('respire.v.02'), Synset('respire.v.01'), Synset('choke.v.01'), Synset('hyperventilate.v.02'), Synset('hyperventilate.v.01'), Synset('aspirate.v.03'), Synset('burp.v.01'), Synset('force_out.v.08'), Synset('hiccup.v.01')]\n",
      "a\n",
      "18156\n",
      "[Synset('able.a.01'), Synset('unable.a.01'), Synset('abaxial.a.01'), Synset('adaxial.a.01'), Synset('acroscopic.a.01'), Synset('basiscopic.a.01'), Synset('abducent.a.01'), Synset('adducent.a.01'), Synset('nascent.a.01'), Synset('emergent.s.02')]\n",
      "r\n",
      "3621\n",
      "[Synset('a_cappella.r.01'), Synset('ad.r.01'), Synset('ce.r.01'), Synset('bc.r.01'), Synset('bce.r.01'), Synset('horseback.r.01'), Synset('barely.r.01'), Synset('just.r.06'), Synset('hardly.r.02'), Synset('anisotropically.r.01')]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "pos_list = [wn.NOUN,wn.VERB,wn.ADJ,wn.ADV]\n",
    "\n",
    "for pos in pos_list:\n",
    "    print(pos)\n",
    "\n",
    "    synsets = list(wn.all_synsets(pos))\n",
    "\n",
    "    print(len(synsets))\n",
    "    print(synsets[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can see that WordNet is dominated by nouns; the vast majority of synsets are nominal, indicated by \"n\". They are represented by an identifier consisting of \n",
    "\n",
    "1. the most prominent synonym\n",
    "2. the part of speech\n",
    "3. an id number (seemingly arbitrary) which distinguishes synsets for which the first of these two are the same.\n",
    "\n",
    "If we know this identifier, we can get the corresponding synset object, using `synset`. Let's start with the very top of the WordNet hierarchy: *entity*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('entity.n.01')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset(\"entity.n.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A more typical way to access synsets in WordNet, though, is by looking up a word to get its `synsets`. Many words have more than one synset, which indicates that it has more than one meaning, and is therefore ambiguous. Lets look at the word *goal*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('goal.n.01'),\n",
       " Synset('finish.n.04'),\n",
       " Synset('goal.n.03'),\n",
       " Synset('goal.n.04')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_synsets = wn.synsets(\"goal\")\n",
    "goal_synsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The synset identifier (which you can get as a string by using the `name()` method for synsets) often isn't terribly helpful for figuring out what a synset means. Fortunately, every synset has a *gloss* or definition associated with it, which can be accessed using the `definition()`. Some synsets also have examples, accessible via the `examples()` method though note that the example may or may not include the specific form you're interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal.n.01\n",
      "the state of affairs that a plan is intended to achieve and that (when achieved) terminates behavior intended to achieve it\n",
      "['the ends justify the means']\n",
      "finish.n.04\n",
      "the place designated as the end (as of a race or journey)\n",
      "['a crowd assembled at the finish', 'he was nearly exhausted as their destination came into view']\n",
      "goal.n.03\n",
      "game equipment consisting of the place toward which players of a game try to advance a ball or puck in order to score points\n",
      "[]\n",
      "goal.n.04\n",
      "a successful attempt at scoring\n",
      "['the winning goal came with less than a minute left to play']\n"
     ]
    }
   ],
   "source": [
    "for synset in goal_synsets:\n",
    "    print(synset.name())\n",
    "    print(synset.definition())\n",
    "    print(synset.examples())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can find the other words associated with a particular synset using the `lemmas()` method, which accesses a corresponding list of `Lemma` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('goal.n.01.goal'), Lemma('goal.n.01.end')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_synsets[0].lemmas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('finish.n.04.finish'),\n",
       " Lemma('finish.n.04.destination'),\n",
       " Lemma('finish.n.04.goal')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_synsets[1].lemmas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Lemmas have a few useful methods. You can access the words (which appear at the end of the 4-part lemma identifiers) using `name()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'goal'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_synsets[0].lemmas()[0].name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each lemma also has a `count` associated with it, which comes from a sense-annotated portion of the Brown corpus called *semcor*. Using these counts, we can guess at which sense of a word is more common. \n",
    "\n",
    "> Note: This is counting how many words have the ultimate lemma of \"goal\". Or see the next cell for clarification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goal_synsets[0].lemmas()[0].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to know which senses of a word are more common, we can iterate over its senses, find the corresponding lemma, and check its counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the state of affairs that a plan is intended to achieve and that (when achieved) terminates behavior intended to achieve it\n",
      "34\n",
      "the place designated as the end (as of a race or journey)\n",
      "1\n",
      "game equipment consisting of the place toward which players of a game try to advance a ball or puck in order to score points\n",
      "0\n",
      "a successful attempt at scoring\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets(\"goal\"):\n",
    "    for lemma in synset.lemmas():\n",
    "        if lemma.name() == \"goal\":\n",
    "            print(synset.definition())\n",
    "            print(lemma.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that we can access WordNet synsets using inflected forms, and this is often a good idea since inflected forms often partially disambiguate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma('watch.v.01.watch')\n",
      "Lemma('watch.v.02.watch')\n",
      "Lemma('watch.v.02.observe')\n",
      "Lemma('watch.v.02.follow')\n",
      "Lemma('watch.v.02.watch_over')\n",
      "Lemma('watch.v.02.keep_an_eye_on')\n",
      "Lemma('watch.v.03.watch')\n",
      "Lemma('watch.v.03.view')\n",
      "Lemma('watch.v.03.see')\n",
      "Lemma('watch.v.03.catch')\n",
      "Lemma('watch.v.03.take_in')\n",
      "Lemma('watch.v.04.watch')\n",
      "Lemma('watch.v.04.look_on')\n",
      "Lemma('watch.v.05.watch')\n",
      "Lemma('watch.v.05.look_out')\n",
      "Lemma('watch.v.05.watch_out')\n",
      "Lemma('watch.v.06.watch')\n",
      "Lemma('determine.v.08.determine')\n",
      "Lemma('determine.v.08.check')\n",
      "Lemma('determine.v.08.find_out')\n",
      "Lemma('determine.v.08.see')\n",
      "Lemma('determine.v.08.ascertain')\n",
      "Lemma('determine.v.08.watch')\n",
      "Lemma('determine.v.08.learn')\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets(\"watched\"):\n",
    "    for lemma in synset.lemmas():\n",
    "        print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Generally, WordNet sysnets are very fine-grained. This is actually a problem because it can be very difficult for both humans and computers to differentiate subtle sense distinctions. Though these distinctions may matter to lexicographers, for many computational applications it makes sense to collapse sense, or simply ignore rare ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watch.n.01\n",
      "a small portable timepiece\n",
      "watch.n.02\n",
      "a period of time (4 or 2 hours) during which some of a ship's crew are on duty\n",
      "watch.n.03\n",
      "a purposeful surveillance to guard or observe\n",
      "watch.n.04\n",
      "the period during which someone (especially a guard) is on duty\n",
      "lookout.n.01\n",
      "a person employed to keep watch for some anticipated event\n",
      "vigil.n.02\n",
      "the rite of staying awake for devotional purposes (especially on the eve of a religious festival)\n",
      "watch.v.01\n",
      "look attentively\n",
      "watch.v.02\n",
      "follow with the eyes or the mind\n",
      "watch.v.03\n",
      "see or watch\n",
      "watch.v.04\n",
      "observe with attention\n",
      "watch.v.05\n",
      "be vigilant, be on the lookout or be careful\n",
      "watch.v.06\n",
      "observe or determine by looking\n",
      "determine.v.08\n",
      "find out, learn, or determine with certainty, usually by making an inquiry or other effort\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets(\"watch\"):\n",
    "    print(synset.name())\n",
    "    print(synset.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example: Let's pick an ambiguous word and try to enumerate its senses. Then we'll see how many senses it has in WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "light.n.01\n",
      "(physics) electromagnetic radiation that can produce a visual sensation\n",
      "light.n.02\n",
      "any device serving as a source of illumination\n",
      "light.n.03\n",
      "a particular perspective or aspect of a situation\n",
      "luminosity.n.01\n",
      "the quality of being luminous; emitting or reflecting light\n",
      "light.n.05\n",
      "an illuminated area\n",
      "light.n.06\n",
      "a condition of spiritual awareness; divine illumination\n",
      "light.n.07\n",
      "the visual effect of illumination on objects or scenes as created in pictures\n",
      "light.n.08\n",
      "a person regarded very fondly\n",
      "light.n.09\n",
      "having abundant light or illumination\n",
      "light.n.10\n",
      "mental understanding as an enlightening experience\n",
      "sparkle.n.01\n",
      "merriment expressed by a brightness or gleam or animation of countenance\n",
      "light.n.12\n",
      "public awareness\n",
      "inner_light.n.01\n",
      "a divine presence believed by Quakers to enlighten and guide the soul\n",
      "light.n.14\n",
      "a visual warning signal\n",
      "lighter.n.02\n",
      "a device for lighting or igniting fuel or charges or fires\n",
      "light.v.01\n",
      "make lighter or brighter\n",
      "light_up.v.05\n",
      "begin to smoke\n",
      "alight.v.01\n",
      "to come to rest, settle\n",
      "ignite.v.01\n",
      "cause to start burning; subject to fire or great heat\n",
      "fall.v.20\n",
      "fall to somebody by assignment or lot\n",
      "unhorse.v.01\n",
      "alight from (a horse)\n",
      "light.a.01\n",
      "of comparatively little physical weight or density\n",
      "light.a.02\n",
      "(used of color) having a relatively small amount of coloring agent\n",
      "light.a.03\n",
      "of the military or industry; using (or being) relatively small or light arms or equipment\n",
      "light.a.04\n",
      "not great in degree or quantity or number\n",
      "light.a.05\n",
      "psychologically light; especially free from sadness or troubles\n",
      "light.a.06\n",
      "characterized by or emitting light\n",
      "unaccented.s.02\n",
      "(used of vowels or syllables) pronounced with little or no stress\n",
      "light.s.08\n",
      "easily assimilated in the alimentary canal; not rich or heavily seasoned\n",
      "light.s.09\n",
      "(used of soil) loose and large-grained in consistency\n",
      "clean.s.03\n",
      "(of sound or color) free from anything that dulls or dims\n",
      "light.s.11\n",
      "moving easily and quickly; nimble\n",
      "light.s.12\n",
      "demanding little effort; not burdensome\n",
      "light.a.13\n",
      "of little intensity or power or force\n",
      "light.a.14\n",
      "(physics, chemistry) not having atomic weight greater than average\n",
      "faint.s.04\n",
      "weak and likely to lose consciousness\n",
      "light.s.16\n",
      "very thin and insubstantial\n",
      "abstemious.s.02\n",
      "marked by temperance in indulgence\n",
      "light.s.18\n",
      "less than the correct or legal or full amount often deliberately so\n",
      "light.s.19\n",
      "having little importance\n",
      "light.s.20\n",
      "intended primarily as entertainment; not serious or profound\n",
      "idle.s.04\n",
      "silly or trivial\n",
      "light.s.22\n",
      "designed for ease of movement or to carry little weight\n",
      "light.s.23\n",
      "having relatively few calories\n",
      "light.s.24\n",
      "(of sleep) easily disturbed\n",
      "easy.s.10\n",
      "casual and unrestrained in sexual behavior\n",
      "lightly.r.02\n",
      "with few burdens\n"
     ]
    }
   ],
   "source": [
    "for synset in wn.synsets(\"light\"):\n",
    "    print(synset.name())\n",
    "    print(synset.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The other key organizing relationship is WordNet is the hypernym/hyponym relation, which is the *is kind of* relation. Put abstractly, if A is a kind of B, then B is the hypernym of A, and A is the hyponym of B. Note that a synset can have multiple hyponyms and multiple hypernyms. However, the latter is much rarer and we won't address it here, which allows us to treat WordNet like a tree.\n",
    "\n",
    "For a more concrete example, a cat is an animal, so \"cat\" is a a *hyponym* of \"animal\", and \"animal\" is a *hypernym* of \"cat\".\n",
    "\n",
    "Let's look at some of these relations in WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_synset = wn.synset(\"cat.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('feline.n.01')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_synset.hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('carnivore.n.01')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_synset.hypernyms()[0].hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('whole.n.02')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_synset.hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('domestic_cat.n.01')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_synset.hyponyms()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word does not have any hyponyms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_synset.hyponyms()[0].hyponyms()[0].hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_synset = wn.synset(\"coin.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('entity.n.01')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money_synset.hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0].hypernyms()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bawbee.n.01'),\n",
       " Synset('bezant.n.01'),\n",
       " Synset('change.n.08'),\n",
       " Synset('crown.n.06'),\n",
       " Synset('denier.n.02'),\n",
       " Synset('dime.n.01'),\n",
       " Synset('dollar.n.03'),\n",
       " Synset('double_eagle.n.02'),\n",
       " Synset('doubloon.n.01'),\n",
       " Synset('ducat.n.01'),\n",
       " Synset('eagle.n.03'),\n",
       " Synset('eightpence.n.01'),\n",
       " Synset('farthing.n.01'),\n",
       " Synset('fivepence.n.01'),\n",
       " Synset('fourpence.n.01'),\n",
       " Synset('guinea.n.01'),\n",
       " Synset('half_crown.n.01'),\n",
       " Synset('half_dollar.n.01'),\n",
       " Synset('half_eagle.n.01'),\n",
       " Synset('halfpenny.n.01'),\n",
       " Synset('louis_d'or.n.01'),\n",
       " Synset('maundy_money.n.01'),\n",
       " Synset('medallion.n.01'),\n",
       " Synset('nickel.n.02'),\n",
       " Synset('ninepence.n.01'),\n",
       " Synset('penny.n.02'),\n",
       " Synset('piece_of_eight.n.01'),\n",
       " Synset('quarter.n.10'),\n",
       " Synset('real.n.03'),\n",
       " Synset('shilling.n.06'),\n",
       " Synset('sixpence.n.01'),\n",
       " Synset('slug.n.03'),\n",
       " Synset('sou.n.01'),\n",
       " Synset('stater.n.01'),\n",
       " Synset('tenpence.n.01'),\n",
       " Synset('threepence.n.01'),\n",
       " Synset('twopence.n.01')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money_synset.hyponyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Every noun synset in WordNet is connected to every other noun synset in WordNet via a path of hypernym/hyponym relationships. If you follow up the hypernyms of any noun far enough, you will reach the *entity.n.01* node. This connection allows for the calculation of similarity measures. The simpliest form of this, `path_similarity` is just the inverse of the number of steps required to go from one synset to another in wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "cat = wn.synset('cat.n.01')\n",
    "coin = wn.synset(\"coin.n.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.path_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058823529411764705"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.path_similarity(coin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Path similarity isn't a great measure because even though it does often get the basic relationships right, it doesn't make good use of its range (0, 1). In this case, it feels like dog and cat should be more similar than 0.2. \n",
    "\n",
    "And there's another serious problem. If we pick siblings higher in the hypernym tree, we will find larger distances than 0.2 between very distinct concepts. (while this should give smaller similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('causal_agent.n.01'),\n",
       " Synset('matter.n.03'),\n",
       " Synset('object.n.01'),\n",
       " Synset('process.n.06'),\n",
       " Synset('substance.n.04'),\n",
       " Synset('thing.n.12')]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('physical_entity.n.01').hyponyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('process.n.06').path_similarity(wn.synset('matter.n.03'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " A more sophisticated measure, `wup_similarity` addresses this problem by using depth instead of distance and features the lowest common subsumer (i.e. the nearest shared hypernym of two synsets); two synsets will have high similarity if their LCS is deep in the heirarchy. The equation is\n",
    "\n",
    "$$\n",
    "wup\\_similarity(A,B) = \\frac{2*depth(LCS(A,B))}{depth(A) + depth(B)}\n",
    "$$\n",
    "\n",
    "Let's draw some trees and see how this formula works.\n",
    "<br>\n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> \n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8571428571428571"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.wup_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1111111111111111"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog.wup_similarity(coin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('process.n.06').wup_similarity(wn.synset('matter.n.03'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are even more sophisticated ways to calcluate similarity using WordNet relations, though they require sense tagged corpora. We can use the equation above, but instead of using the WordNet *depth* of A, B, and their LCS, we use their *information* based on their probability in a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Though hyponym/hypernym form the core of WordNet, it has a several other relationships between synsets. Meronymy/holonymy is the *is part of* relation, if A is a part of B, then A is meronym of B, and B is a holonym of A. WordNet distinguishes between `part_meronyms` and `substance_meronyms`\n",
    "\n",
    "\"wheel\" is *meronym* of \"car\", and \"car\" is a *holonym* of \"wheel\".  Unlike the hypernym/hyponym relationship, A is not \"belonging to a smaller class\" than B - B actually contains A.  This is sometimes also referred to as a *has a* relation: \"A car has a wheel\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('accelerator.n.01'),\n",
       " Synset('air_bag.n.01'),\n",
       " Synset('auto_accessory.n.01'),\n",
       " Synset('automobile_engine.n.01'),\n",
       " Synset('automobile_horn.n.01'),\n",
       " Synset('buffer.n.06'),\n",
       " Synset('bumper.n.02'),\n",
       " Synset('car_door.n.01'),\n",
       " Synset('car_mirror.n.01'),\n",
       " Synset('car_seat.n.01'),\n",
       " Synset('car_window.n.01'),\n",
       " Synset('fender.n.01'),\n",
       " Synset('first_gear.n.01'),\n",
       " Synset('floorboard.n.02'),\n",
       " Synset('gasoline_engine.n.01'),\n",
       " Synset('glove_compartment.n.01'),\n",
       " Synset('grille.n.02'),\n",
       " Synset('high_gear.n.01'),\n",
       " Synset('hood.n.09'),\n",
       " Synset('luggage_compartment.n.01'),\n",
       " Synset('rear_window.n.01'),\n",
       " Synset('reverse.n.02'),\n",
       " Synset('roof.n.02'),\n",
       " Synset('running_board.n.01'),\n",
       " Synset('stabilizer_bar.n.01'),\n",
       " Synset('sunroof.n.01'),\n",
       " Synset('tail_fin.n.02'),\n",
       " Synset('third_gear.n.01'),\n",
       " Synset('window.n.02')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car = wn.synset('car.n.01')\n",
    "#my code here\n",
    "car.part_meronyms()\n",
    "#my code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('beam.n.02'),\n",
       " Synset('chopping_block.n.01'),\n",
       " Synset('lumber.n.01'),\n",
       " Synset('spindle.n.02')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wood = wn.synset('wood.n.01')\n",
    "wood.substance_holonyms()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also antonyms in WordNet, though note that they are tied to particular lemmas! Why? - unlike synonyms, which all kind of mean the same thing, antonyms are often very specific to one meaning.  Consider \"big/little brother\" - we can't say \"small brother\"! And they are much more common with adjectives, though there are nouns with antonyms too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('abstract.a.01.abstract')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_syn = wn.synset('abstract.a.01')\n",
    "abstract_syn.lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('concrete.a.01.concrete')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_syn.lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('brother.n.01.brother')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('sister.n.01').lemmas()[0].antonyms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, NLTK only has the English WordNet, but WordNets for other languages exist, see [this site](http://globalwordnet.org/resources/wordnets-in-the-world/). NTLK does include non-English lemmas for English synsets, via the [Open Multilingual WordNet (OMW)](http://compling.hss.ntu.edu.sg/omw/). This provides a nice multilingual lexicon, and allows you to calculate things like WordNet distances for other languages using the English WordNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw to /Users/lxy/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---eng----\n",
      "dog\n",
      "domestic_dog\n",
      "Canis_familiaris\n",
      "---als----\n",
      "---arb----\n",
      "كلْب\n",
      "---bul----\n",
      "куче\n",
      "---cat----\n",
      "ca\n",
      "canis_familiaris\n",
      "gos\n",
      "gos_domèstic\n",
      "---cmn----\n",
      "犬\n",
      "狗\n",
      "---dan----\n",
      "hund\n",
      "køter\n",
      "vovhund\n",
      "vovse\n",
      "---ell----\n",
      "σκύλος_γένους_Canis_familiaris\n",
      "---eus----\n",
      "or\n",
      "txakur\n",
      "zakur\n",
      "---fas----\n",
      "---fin----\n",
      "Canis_familiaris\n",
      "koira\n",
      "---fra----\n",
      "canis_familiaris\n",
      "chien\n",
      "---glg----\n",
      "can\n",
      "Canis_familiaris\n",
      "---heb----\n",
      "---hrv----\n",
      "Canis_lupus_familiaris\n",
      "domaći_pas\n",
      "pas\n",
      "---ind----\n",
      "anjing\n",
      "---ita----\n",
      "cane\n",
      "Canis_familiaris\n",
      "---jpn----\n",
      "イヌ\n",
      "ドッグ\n",
      "洋犬\n",
      "犬\n",
      "飼犬\n",
      "飼い犬\n",
      "---nld----\n",
      "hond\n",
      "joekel\n",
      "---nno----\n",
      "bisk\n",
      "hund\n",
      "kjøter\n",
      "---nob----\n",
      "bisk\n",
      "hund\n",
      "kjøter\n",
      "---pol----\n",
      "pies\n",
      "pies_domowy\n",
      "---por----\n",
      "cachorra\n",
      "cachorro\n",
      "cadela\n",
      "cão\n",
      "---qcn----\n",
      "---slv----\n",
      "canis_familiaris\n",
      "pes\n",
      "---spa----\n",
      "can\n",
      "perro\n",
      "---swe----\n",
      "hund\n",
      "---tha----\n",
      "หมา\n",
      "สุนัข\n",
      "หมาบ้าน\n",
      "---zsm----\n",
      "anjing\n"
     ]
    }
   ],
   "source": [
    "for lang in wn.langs():\n",
    "    print(\"---\" + lang + \"----\")\n",
    "    \n",
    "    for lemma in dog.lemma_names(lang):\n",
    "        print(lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Word Sense Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Word Sense Disambiguation is the task of determining which sense a particular instance of a word is. Given a collection of possible senses (synsets) for a particular word, we can view it as a classification task for each ambiguous word token. \n",
    "\n",
    "WSD is a fundamental problem in computational linguistics, but it actually rarely included explicitly in pipelines for major semantic tasks. One reason is that good, supervised WSD requires a separate model for *each ambiguous word type*, which a major overhead even assuming you have reliable annotations of sense (which are expensive to create). But note that some of the sophisticated neural methods like BERT are clearly doing implicit WSD. \n",
    "\n",
    "To get at another reason why WSD isn't a standard part of most NLP pipelines, let's look at some examples of the word \"interest\" from two corpora, the Treebank and the Gutenberg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interest.n.01\n",
      "a sense of concern with and curiosity about someone or something\n",
      "sake.n.01\n",
      "a reason for wanting something done\n",
      "interest.n.03\n",
      "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "interest.n.05\n",
      "(law) a right or legal share of something; a financial involvement with something\n",
      "-----\n",
      "Treebank\n",
      "----\n",
      "Yields on money-market mutual funds continued *-1 to slide , amid signs that portfolio managers expect further declines in interest rates .\n",
      "Longer maturities are thought *-1 to indicate declining interest rates because they permit portfolio managers to retain relatively higher rates for a longer period .\n",
      "Nevertheless , said *T*-1 Brenda Malizia Negus , editor of Money Fund Report , yields `` may blip up again before they blip down '' because of recent rises in short-term interest rates .\n",
      "J.P. Bolduc , vice chairman of W.R. Grace & Co. , which *T*-10 holds a 83.4 % interest in this energy-services company , was elected *-10 a director .\n",
      "In August , the commission ruled that between $ 190 million and $ 195 million *U* of the plant 's construction cost was unreasonable and should be refunded *-1 , plus interest .\n",
      "-----\n",
      "Gutenberg\n",
      "-----\n",
      "As she sat one morning , looking forward to exactly such a close of the present day , a note was brought from Mrs . Goddard , requesting , in most respectful terms , to be allowed to bring Miss Smith with her ; a most welcome request : for Miss Smith was a girl of seventeen , whom Emma knew very well by sight , and had long felt an interest in , on account of her beauty .\n",
      "A degree or two lower , and a creditable appearance might interest me ; I might hope to be useful to their families in some way or other .\n",
      "Emma must do Harriet good : and by supplying her with a new object of interest , Harriet may be said to do Emma good .\n",
      "I have a very sincere interest in Emma .\n",
      "Isabella does not seem more my sister ; has never excited a greater interest ; perhaps hardly so great .\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import treebank,gutenberg\n",
    "\n",
    "def print_10_examples(corpus, target):\n",
    "    examples = []\n",
    "    for sent in corpus.sents():\n",
    "        for word in sent:\n",
    "            if word.lower() == target:\n",
    "                examples.append(\" \".join(sent))\n",
    "                break     # exit out of a loop when this external condition is triggered\n",
    "        if len(examples) == 5:\n",
    "            break\n",
    "    print(\"\\n\".join(examples))\n",
    "\n",
    "for synset in wn.synsets(\"interest\")[:5]:\n",
    "    print(synset.name())\n",
    "    print(synset.definition())\n",
    "\n",
    "print(\"-----\\nTreebank\\n----\")\n",
    "print_10_examples(treebank,\"interest\")\n",
    "print(\"-----\\nGutenberg\\n-----\")\n",
    "print_10_examples(gutenberg,\"interest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In any particular corpus, one sense (or a small group of closely related senses) will often dominate. This means that is often very difficult to beat the *most frequent sense* (MFS) baseline accuracy, i.e. the accuracy if the system just always guessed the most common sense.\n",
    "\n",
    "NLTK includes a corpus called semcor which (as noted earlier) is part of the Brown corpus which has been sense tagged (it is also chunked, with senses assigned to the chunks rather than words). Let's take a look at it, and then use it to calculate the MFS accuracy for the word *interest* in that corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Tree('DT', ['The']), Tree(Lemma('group.n.01.group'), [Tree('NE', [Tree('NNP', ['Fulton', 'County', 'Grand', 'Jury'])])]), Tree(Lemma('state.v.01.say'), [Tree('VB', ['said'])]), Tree(Lemma('friday.n.01.Friday'), [Tree('NN', ['Friday'])]), Tree('DT', ['an']), Tree(Lemma('probe.n.01.investigation'), [Tree('NN', ['investigation'])]), Tree('IN', ['of']), Tree(Lemma('atlanta.n.01.Atlanta'), [Tree('NN', ['Atlanta'])]), Tree('POS', [\"'s\"]), Tree(Lemma('late.s.03.recent'), [Tree('JJ', ['recent'])]), Tree(Lemma('primary.n.01.primary_election'), [Tree('NN', ['primary', 'election'])]), Tree(Lemma('produce.v.04.produce'), [Tree('VB', ['produced'])]), Tree(None, ['``']), Tree('DT', ['no']), Tree(Lemma('evidence.n.01.evidence'), [Tree('NN', ['evidence'])]), Tree(None, [\"''\"]), Tree('IN', ['that']), Tree('DT', ['any']), Tree(Lemma('abnormality.n.04.irregularity'), [Tree('NN', ['irregularities'])]), Tree(Lemma('happen.v.01.take_place'), [Tree('VB', ['took', 'place'])]), Tree(None, ['.'])]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import nltk\n",
    "# nltk.download('semcor')\n",
    "from nltk.corpus import semcor\n",
    "\n",
    "print(semcor.tagged_sents(tag='sense')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n"
     ]
    }
   ],
   "source": [
    "wanted_word = \"interest\"\n",
    "sense_counts = defaultdict(int)\n",
    "\n",
    "for sent in semcor.tagged_sents(tag='sense'):\n",
    "    for chunk in sent:\n",
    "        lemma = chunk.label()\n",
    "        try:\n",
    "            lemma_name = lemma.name()\n",
    "        except:\n",
    "            lemma_name = None\n",
    "        if lemma_name == wanted_word:\n",
    "            sense_counts[lemma.synset().name()] += 1\n",
    "            if sum(sense_counts.values()) % 10 == 0:\n",
    "                print(sum(sense_counts.values()))\n",
    "        #except:\n",
    "        #    pass\n",
    "                \n",
    "print(sense_counts)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a sense of concern with and curiosity about someone or something\n",
      "0.3904109589041096\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('interest.n.01').definition())\n",
    "print(max(sense_counts.values())/sum(sense_counts.values()))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's build a simple decision tree classifier which uses the words appearing immediately before and after as features, and see if we can beat this baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37176"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(semcor.tagged_sents(tag='hi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tree('DT', ['The']),\n",
       " Tree(Lemma('group.n.01.group'), [Tree('NE', [Tree('NNP', ['Fulton', 'County', 'Grand', 'Jury'])])]),\n",
       " Tree(Lemma('state.v.01.say'), [Tree('VB', ['said'])]),\n",
       " Tree(Lemma('friday.n.01.Friday'), [Tree('NN', ['Friday'])]),\n",
       " Tree('DT', ['an']),\n",
       " Tree(Lemma('probe.n.01.investigation'), [Tree('NN', ['investigation'])]),\n",
       " Tree('IN', ['of']),\n",
       " Tree(Lemma('atlanta.n.01.Atlanta'), [Tree('NN', ['Atlanta'])]),\n",
       " Tree('POS', [\"'s\"]),\n",
       " Tree(Lemma('late.s.03.recent'), [Tree('JJ', ['recent'])]),\n",
       " Tree(Lemma('primary.n.01.primary_election'), [Tree('NN', ['primary', 'election'])]),\n",
       " Tree(Lemma('produce.v.04.produce'), [Tree('VB', ['produced'])]),\n",
       " Tree(None, ['``']),\n",
       " Tree('DT', ['no']),\n",
       " Tree(Lemma('evidence.n.01.evidence'), [Tree('NN', ['evidence'])]),\n",
       " Tree(None, [\"''\"]),\n",
       " Tree('IN', ['that']),\n",
       " Tree('DT', ['any']),\n",
       " Tree(Lemma('abnormality.n.04.irregularity'), [Tree('NN', ['irregularities'])]),\n",
       " Tree(Lemma('happen.v.01.take_place'), [Tree('VB', ['took', 'place'])]),\n",
       " Tree(None, ['.'])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semcor.tagged_sents(tag='hi')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [documentation for semcor](https://www.nltk.org/_modules/nltk/corpus/reader/semcor.html) for more detail.\n",
    "\n",
    "`semcor.tagged_sents` returns sentences that are tagged as one situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5549425287356322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "correct_senses = []\n",
    "feature_dicts = []\n",
    "\n",
    "for sent in semcor.tagged_sents(tag='sense'):\n",
    "    for i in range(len(sent)):\n",
    "        chunk = sent[i]\n",
    "        lemma = chunk.label()\n",
    "        try: \n",
    "            lemma_name = lemma.name()\n",
    "        except:\n",
    "            lemma_name = None\n",
    "        if lemma_name == wanted_word:\n",
    "            correct_senses.append(lemma.synset().name())\n",
    "            feature_dict = {}\n",
    "            if i > 0:\n",
    "                feature_dict[\"BEFORE_\" + sent[i-1].leaves()[-1].lower()] = 1\n",
    "            if i < len(sent):\n",
    "                feature_dict[\"AFTER_\" + sent[i+1].leaves()[-1].lower()] = 1\n",
    "            feature_dicts.append(feature_dict)\n",
    "\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "X = vectorizer.fit_transform(feature_dicts)\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "print(np.mean(cross_val_score(clf,X,correct_senses,cv=5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We could probably do better at this task if we include a larger context around the word, and generalize some of the features. \n",
    "\n",
    "A classic approach to WSD which doesn't rely on tagged examples in a corpus is the \"unsupervised\" **Lesk algorithm**, which instead uses the information in the gloss in Wordnet. The simpliest version of Lesk, which is included in NLTK, just picks the sense whose definition has the most word overlap with the context around the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treebank.tagged_sents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> See [Lesk algorithm document](https://www.nltk.org/howto/wsd.html) for more usage information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('savings_bank.n.02')\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "from nltk.wsd import lesk\n",
    "sent = ['I', 'went', 'to', 'the', 'bank', 'to', 'deposit', 'money', '.']\n",
    "print(lesk(sent, 'bank', 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yields on money-market mutual funds continued *-1 to slide , amid signs that portfolio managers expect further declines in interest rates .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "Longer maturities are thought *-1 to indicate declining interest rates because they permit portfolio managers to retain relatively higher rates for a longer period .\n",
      "sake.n.01\n",
      "a reason for wanting something done\n",
      "Nevertheless , said *T*-1 Brenda Malizia Negus , editor of Money Fund Report , yields `` may blip up again before they blip down '' because of recent rises in short-term interest rates .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "J.P. Bolduc , vice chairman of W.R. Grace & Co. , which *T*-10 holds a 83.4 % interest in this energy-services company , was elected *-10 a director .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "In August , the commission ruled that between $ 190 million and $ 195 million *U* of the plant 's construction cost was unreasonable and should be refunded *-1 , plus interest .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "Last month , Judge Curry set the interest rate on the refund at 9 % .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "Gary Hoffman , a Washington lawyer specializing in intellectual-property cases , said 0 the threat of U.S. retaliation , combined * with a growing recognition that * protecting intellectual property is in a country 's own interest , prompted the improvements made * by South Korea , Taiwan and Saudi Arabia .\n",
      "interest.n.01\n",
      "a sense of concern with and curiosity about someone or something\n",
      "Mr. Rapanelli recently has said 0 the government of President Carlos Menem , who *T*-29 took office July 8 , feels 0 a significant reduction of principal and interest is the only way 0 the debt problem may be solved *-31 *T*-1 .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "That stake , together with its convertible preferred stock holdings , gives Faulding the right * to increase its interest to 70 % of Moleculon 's voting stock .\n",
      "interest.n.05\n",
      "(law) a right or legal share of something; a financial involvement with something\n",
      "The purchases show the strong interest of Japanese investors in U.S. mortgage-based instruments , Fannie Mae 's chairman , David O. Maxwell , said 0 *T*-1 at a news conference .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "First , they are designed *-1 to eliminate the risk of prepayment -- mortgage-backed securities can be retired *-43 early if interest rates decline , and such prepayment forces investors to redeploy their money at lower rates .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "At the same time , the drop in interest rates since the spring has failed *-1 to revive the residential construction industry .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "David Berson , economist for the Mortgage Bankers Association , predicted 0 the drop in interest rates eventually will boost spending on single-family homes , but probably not until early next year .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "The Toronto-based real estate concern said 0 each bond warrant entitles the holder to buy C$ 1,000 *U* principal amount of debentures at par plus accrued interest to the date of purchase .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "He also said that after the charges , and *-1 `` assuming no dramatic fluctuation in interest rates , the company expects *-1 to achieve near-record earnings in 1990 . ''\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "The fire is also fueled *-1 by growing international interest in Japanese behavior .\n",
      "interest.n.03\n",
      "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
      "Meanwhile , traders in Tokyo say that the prospect of lower U.S. interest rates has spurred dollar buying by Japanese institutions .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "The market again showed little interest in further evidence of a slowing U.S. economy , and traders note that the market in recent weeks has taken its cues more from Wall Street than U.S. economic indicators .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "Signs of a slowing economy are increasing pressure *ICH*-2 on the Federal Reserve * to cut short-term interest rates , but it *EXP*-1 is n't clear whether the central bank will do so .\n",
      "interest.n.03\n",
      "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
      "The Fed cut the key federal funds interest rate by about 0.25 percentage point to 8.75 % after the Oct. 13 stock market plunge , but has shown no sign of movement since .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "`` Each day that Congress fails *-1 to act *T*-2 ... will cause additional disruption in our borrowing schedule , * possibly resulting in higher interest costs to the taxpayer , '' Treasury Secretary Nicholas Brady said *T*-3 in a speech prepared * for delivery last night to a group of bankers .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "Heightened Japanese interest in American small business parallels an acceleration of investments giving Japanese companies control of large , highly visible U.S. corporations , such as Columbia Pictures Entertainment Inc .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "Last year , Mitsubishi International Corp. , the New York-based arm of Mitsubishi Corp. , bought controlling interest in the glass company in a joint venture with Ronald Bodner , a glass industry executive and Mitsubishi consultant .\n",
      "interest.n.01\n",
      "a sense of concern with and curiosity about someone or something\n",
      "Adds *ICH*-1 Takeshi Kondo , senior vice president of C. Itoh America Inc. : `` We have a great interest in * making investments , particularly in new ventures . ''\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "Mr. Klauser says 0 Mitsui has 75 U.S. subsidiaries in which it holds 35 % interest or more *T*-1 and the trading company hopes *-2 to double the number of its U.S. affiliates in 1990 .\n",
      "interest.n.03\n",
      "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
      "For nearly a decade , banks have competed for customers primarily with the interest rates 0 they pay *T*-1 on their deposits and charge *T*-1 on their loans .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "The sweeping nature of the bill draws a variety of special interest amendments , running from an import exemption for a California airplane museum to a small but intriguing struggle among sugar producing nations over the fate of Panama 's quota of exports to the profitable U.S. market .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "But Rep. Hammerschmidt said that the provision , which he dubbed *T*-2 a `` special interest '' amendment , was likely *-1 to make the bill even more controversial .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "The key U.S. and foreign annual interest rates below are a guide to general levels but do n't always represent actual transactions .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "Olympia Broadcasting Corp. said 0 it did n't make a $ 1.64 million *U* semiannual interest payment due yesterday on $ 23.4 million *U* of senior subordinated debentures .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "Thus , an institution obligated * to make fixed-rate interest payments on debt swaps the payments with another making floating-rate payments .\n",
      "interest.n.05\n",
      "(law) a right or legal share of something; a financial involvement with something\n",
      "As interest rates rose , municipalities owed the banks more than the banks were paying them .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "And they believe 0 the Big Board , under Mr. Phelan , has abandoned their interest .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "`` I 'm starting *-1 to see more business transactions , '' says *T*-2 Andrea West of American Telephone & Telegraph Co. , *-3 noting growing interest in use of 900 service for stock sales , software tutorials and even service contracts .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "`` I 'd much rather see them dealing with interest rates and the deficit . ''\n",
      "interest.n.01\n",
      "a sense of concern with and curiosity about someone or something\n",
      "There is $ 30.9 million *U* of fourth series bonds , the interest on which *T*-1 is not subject to the federal alternative minimum tax .\n",
      "interest.n.03\n",
      "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
      "Its backers fielded every important interest on their team -- a popular mayor , the Chamber of Commerce , the major media -- and spent $ 100,000 *U* on promotion .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "Congress could create a compensation program 0 *T*-1 to help such victims while *-2 protecting the national interest in * encouraging new drugs .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "Institutions mostly remained on the sidelines because of uncertainty regarding interest rates and the dollar .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "Due to continuingly high gold prices tied * to uncertainty about the U.S. currency , investor interest was directed *-1 toward oil and mining shares , which traders called *T*-2 a `` defensive '' action frequently taken * when the dollar is expected *-4 to fall *T*-3 or during times of inflation .\n",
      "interest.n.01\n",
      "a sense of concern with and curiosity about someone or something\n",
      "Dealers said 0 most investor interest was focused *-1 on defensive blue-chip stocks , particularly those with limited U.K. exposure .\n",
      "interest.n.05\n",
      "(law) a right or legal share of something; a financial involvement with something\n",
      "Total return measures price changes and interest income .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "An official for the lead underwriter declined *-1 to comment on the reason for the delay , but market participants speculated that a number of factors , including a lack of investor interest , were responsible .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "*-1 Bucking the market trend , an issue of $ 130 million *U* general obligation distributable state aid bonds from Detroit , Mich. , apparently drew solid investor interest .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "West German dealers said 0 there was little interest in Treasury bonds ahead of Thursday 's new government bond issue .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "The rating concern said 0 the textile and clothing company 's interest expense exceeds operating profit `` by a wide margin '' and it noted United 's estimated after-tax loss of $ 24 million *U* for the year ended June 30 .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n",
      "Although takeover experts said 0 they doubted 0 Mr. Steinberg will make a bid by himself , the application by his Reliance Group Holdings Inc. could signal his interest in * helping *-1 revive a failed labor-management bid .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "Younkers management is likely *-1 to buy a 10 % to 20 % *U* interest in the chain in January , said 0 *T*-2 Fred S. Hubbell , Equitable 's president and chief executive officer .\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "The company also cited interest costs and amortization of goodwill as factors in the loss .\n",
      "interest.n.06\n",
      "(usually plural) a social group whose members control some field of activity and who have common aims\n",
      "Trading is expected *-1 to remain subdued as the market awaits tomorrow 's release of the jobs data with the hope that it will point toward a decline in interest rates .\n",
      "interest.n.03\n",
      "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
      "The thrift said that `` after these charges and * assuming no dramatic fluctuation in interest rates , the association expects *-1 to achieve near record earnings in 1990 . ''\n",
      "pastime.n.01\n",
      "a diversion that occupies one's time and thoughts (usually pleasantly)\n",
      "The Fed is coming under pressure * to cut short-term interest rates due to the apparent slowing of the economy .\n",
      "interest.n.03\n",
      "the power of attracting or holding one's attention (because it is unusual or exciting etc.)\n",
      "In the case of copper , he said 0 *T*-2 , the upbeat mood of stocks was reflected *-1 in demand for futures contracts because a stronger economy means greater buying interest for the metal .\n",
      "interest.n.04\n",
      "a fixed charge for borrowing money; usually a percentage of the amount borrowed\n"
     ]
    }
   ],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "target = \"interest\"\n",
    "\n",
    "for sent in treebank.tagged_sents():\n",
    "    for word,pos in sent:\n",
    "        if word.lower() == target:\n",
    "            print(\" \".join([word for word,pos in sent]))\n",
    "            synset = lesk([word.lower() for word,pos in sent], 'interest', pos[0].lower())\n",
    "            print(synset.name())\n",
    "            print(synset.definition())\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are various problems with the simple Lesk. One issue is that function words can end up having a major effect; this can be mitigated by using a stopword list. Lesk works much better if you don't rely on direct word overlap but rather general semantic relatedness, for instance using the word representations we will see later.\n",
    "\n",
    "<br>\n",
    "\n",
    "In certain cases, it is possible to make use of unlabelled corpora for WSD, if you start with a bit of knowledge. If you know that \"rates\" is an unambigious indicator of the money sense of \"interest\", you can use that as a jumping off point to learn more about that sense to build a supervised classifier. This is semi-supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's count the words that appear near \"interest rates\" and \"interest in\" in the Brown and look at them to see if they could be used to distinguish the sense of \"interest\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'The': 1,\n",
       "         'Fulton': 1,\n",
       "         'County': 1,\n",
       "         'Grand': 1,\n",
       "         'Jury': 1,\n",
       "         'said': 1,\n",
       "         'Friday': 1,\n",
       "         'an': 1,\n",
       "         'investigation': 1,\n",
       "         'of': 1,\n",
       "         \"Atlanta's\": 1,\n",
       "         'recent': 1,\n",
       "         'primary': 1,\n",
       "         'election': 1,\n",
       "         'produced': 1,\n",
       "         '``': 1,\n",
       "         'no': 1,\n",
       "         'evidence': 1,\n",
       "         \"''\": 1,\n",
       "         'that': 1,\n",
       "         'any': 1,\n",
       "         'irregularities': 1,\n",
       "         'took': 1,\n",
       "         'place': 1,\n",
       "         '.': 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "cnt.update(['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
    ")\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.']\n",
      "['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.']\n",
      "['The', 'September-October', 'term', 'jury', 'had', 'been', 'charged', 'by', 'Fulton', 'Superior', 'Court', 'Judge', 'Durwood', 'Pye', 'to', 'investigate', 'reports', 'of', 'possible', '``', 'irregularities', \"''\", 'in', 'the', 'hard-fought', 'primary', 'which', 'was', 'won', 'by', 'Mayor-nominate', 'Ivan', 'Allen', 'Jr.', '.']\n",
      "['``', 'Only', 'a', 'relative', 'handful', 'of', 'such', 'reports', 'was', 'received', \"''\", ',', 'the', 'jury', 'said', ',', '``', 'considering', 'the', 'widespread', 'interest', 'in', 'the', 'election', ',', 'the', 'number', 'of', 'voters', 'and', 'the', 'size', 'of', 'this', 'city', \"''\", '.']\n",
      "['The', 'jury', 'said', 'it', 'did', 'find', 'that', 'many', 'of', \"Georgia's\", 'registration', 'and', 'election', 'laws', '``', 'are', 'outmoded', 'or', 'inadequate', 'and', 'often', 'ambiguous', \"''\", '.']\n"
     ]
    }
   ],
   "source": [
    "# Here gives you an idea how the brown.sents() looks like\n",
    "from nltk.corpus import brown\n",
    "for sent in brown.sents()[:5]:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.corpus import brown\n",
    "\n",
    "def get_context_around_words(word1,word2):\n",
    "    '''given a pair of words, identify cases where the two words appear,\n",
    "    and get other words in the sentence context'''\n",
    "    context_counter = Counter()\n",
    "    for sent in brown.sents():\n",
    "        \n",
    "        for i in range(len(sent) - 1):\n",
    "            if sent[i].lower() == word1 and sent[i + 1].lower() == word2:\n",
    "                context_counter.update(sent[:i])\n",
    "                context_counter.update(sent[i+2:])\n",
    "        \n",
    "    return context_counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({',': 122, 'the': 113, 'of': 74, '.': 66, 'and': 57, 'to': 51, 'a': 41, 'in': 38, 'that': 27, 'is': 22, 'their': 22, ';': 22, 'for': 20, 'have': 16, 'his': 16, 'was': 14, 'an': 14, '``': 13, 'he': 13, \"''\": 12, 'which': 12, 'by': 11, 'The': 11, 'who': 10, 'with': 10, 'her': 10, 'been': 10, 'on': 9, 'be': 9, 'or': 9, 'this': 8, 'from': 8, 'has': 8, 'had': 8, 'are': 7, 'it': 7, 'not': 6, 'interest': 6, 'about': 5, 'at': 5, 'as': 5, 'old': 5, '(': 5, ')': 5, 'many': 5, 'His': 5, 'fact': 5, 'would': 5, 'school': 5, 'own': 5, 'they': 5, 'out': 4, 'A': 4, 'will': 4, 'than': 4, 'new': 4, 'him': 4, 'no': 4, 'I': 4, 'any': 4, 'one': 4, 'He': 4, 'public': 4, 'jazz': 4, '--': 4, 'In': 4, 'up': 4, 'county': 3, 'others': 3, 'later': 3, 'even': 3, 'those': 3, 'between': 3, 'State': 3, 'other': 3, 'political': 3, 'people': 3, 'enough': 3, 'take': 3, 'much': 3, 'American': 3, 'how': 3, 'personal': 3, 'must': 3, 'Massachusetts': 3, 'men': 3, 'business': 3, 'affairs': 3, 'but': 3, 'often': 3, 'little': 3, 'part': 3, 'group': 3, 'promote': 3, 'social': 3, 'society': 3, 'few': 3, 'paper': 3, 'when': 3, 'said': 2, 'election': 2, 'number': 2, 'Although': 2, 'rule': 2, 'added': 2, 'lines': 2, 'members': 2, 'nothing': 2, 'these': 2, 'types': 2, 'reason': 2, 'began': 2, 'early': 2, 'state': 2, 'cannot': 2, 'power': 2, 'welfare': 2, 'national': 2, 'late': 2, 'renewed': 2, 'art': 2, ':': 2, 'were': 2, 'back': 2, 'into': 2, 'England': 2, 'eat': 2, 'Dr.': 2, 'only': 2, 'yet': 2, 'some': 2, 'longer': 2, 'boating': 2, 'unusual': 2, 'stimulate': 2, 'philosophical': 2, 'first': 2, 'Some': 2, 'One': 2, 'you': 2, 'life': 2, 'When': 2, 'put': 2, 'slaves': 2, 'daughter': 2, 'expressed': 2, 'led': 2, 'career': 2, 'training': 2, 'skill': 2, 'becomes': 2, 'just': 2, 'another': 2, 'Ruth': 2, 'still': 2, 'face': 2, 'Joe': 2, 'Hoyt': 2, 'Dugan': 2, 'seemed': 2, 'rather': 2, 'pure': 2, 'simple': 2, 'give': 2, 'them': 2, 'experience': 2, 'its': 2, 'more': 2, 'Samuel': 2, 'work': 2, 'It': 2, 'attempt': 2, 'treatment': 2, 'problems': 2, 'two': 2, 'showed': 2, 'our': 2, 'letters': 2, 'previous': 2, 'purpose': 2, 'ballet': 2, 'Mr.': 2, 'precision': 2, 'use': 2, 'small': 2, 'emphasis': 2, 'really': 2, 'wanted': 2, 'way': 2, 'either': 2, 'questions': 2, 'after': 2, 'years': 2, 'playmates': 2, 'age': 2, 'increases': 2, 'adults': 2, 'decreases': 2, 'play': 2, 'teacher': 2, 'child': 2, 'values': 2, 'artist': 2, 'connoisseur': 2, 'time': 2, 'so': 2, 'hats': 2, 'She': 2, 'formal': 2, 'study': 2, 'religion': 2, 'waned': 2, 'sixteen': 2, 'substituted': 2, 'Asian': 2, 'Only': 1, 'relative': 1, 'handful': 1, 'such': 1, 'reports': 1, 'received': 1, 'jury': 1, 'considering': 1, 'widespread': 1, 'voters': 1, 'size': 1, 'city': 1, 'pointed': 1, 'mandatory': 1, 'legislation': 1, 'impinging': 1, 'home': 1, 'basically': 1, 'distasteful': 1, 'vital': 1, 'results': 1, 'transcended': 1, 'cheery': 1, 'smile': 1, 'compassionate': 1, 'practical': 1, 'down-to-earth': 1, 'approach': 1, 'Two': 1, 'panel': 1, 'told': 1, 'court': 1, 'receiving': 1, 'telephone': 1, 'calls': 1, 'homes': 1, 'anonymous': 1, 'persons': 1, 'expressing': 1, 'trial': 1, 'Beadle': 1, 'rare': 1, 'scientist': 1, 'takes': 1, 'money': 1, 'matters': 1, 'If': 1, 'done': 1, 'prospect': 1, 'road': 1, 'default': 1, '1962': 1, 'Both': 1, 'existence': 1, 'legislative': 1, 'libraries': 1, 'Albany': 1, '1950': 1, 'creation': 1, 'legislature': 1, 'library': 1, 'systems': 1, 'financed': 1, 'governments': 1, 'matching': 1, 'funds': 1, 'Controller': 1, 'Arthur': 1, 'Levitt': 1, 'hand': 1, 'effectively': 1, 'deny': 1, 'chosen': 1, 'candidate': 1, 'party': 1, 'leaders': 1, 'shown': 1, 'livelier': 1, \"city's\": 1, 'move': 1, 'establishment': 1, 'seashore': 1, 'park': 1, '30,000': 1, 'acres': 1, 'Cape': 1, 'Cod': 1, 'Provincetown': 1, 'Chatham': 1, 'strengthened': 1, 'President': 1, \"Kennedy's\": 1, 'area': 1, 'Seen': 1, 'decorating': 1, 'circles': 1, 'embroidery': 1, 'visited': 1, 'glad': 1, 'government': 1, 'heart': 1, 'misery': 1, 'Latter-day': 1, 'Elizabethan': 1, 'singing': 1, 'dates': 1, 'well': 1, 'nineteenth': 1, 'century': 1, 'ahead': 1, 'similar': 1, 'revivals': 1, 'countries': 1, 'And': 1, 'wake': 1, 'affluence': 1, 'techniques': 1, 'processing': 1, 'comes': 1, 'what': 1, 'affects': 1, 'health': 1, 'Despite': 1, 'distaste': 1, 'obesity': 1, 'disgusting': 1, 'Keys': 1, 'incidental': 1, 'Americans': 1, 'survived': 1, 'because': 1, 'symbolism': 1, 'divination': 1, 'magic': 1, 'persisted': 1, 'Han': 1, 'dynasty': 1, 'succeeded': 1, 'reuniting': 1, 'China': 1, 'keeping': 1, 'together': 1, 'period': 1, '202': 1, 'B.C.': 1, 'A.D.': 1, '220': 1, 'technology': 1, 'engine': 1, 'hull': 1, 'design': 1, 'largely': 1, 'responsible': 1, 'plentiful': 1, 'Industry': 1, 'safety': 1, 'goes': 1, 'farther': 1, 'old-time': 1, 'bridges': 1, 'over': 1, 'Merrimac': 1, 'River': 1, 'respects': 1, 'site': 1, 'overlooks': 1, 'harbor': 1, 'river': 1, 'may': 1, 'offer': 1, 'activities': 1, 'traffic': 1, 'At': 1, '12': 1, 'Hans': 1, 'sufficiently': 1, 'mature': 1, 'help': 1, 'father': 1, 'apothecary': 1, 'shop': 1, 'helped': 1, 'medicine': 1, 'science': 1, 'broad': 1, 'literary': 1, 'movements': 1, 'opened': 1, 'doors': 1, 'finding': 1, 'relationship': 1, 'voltaic': 1, 'electricity': 1, 'magnetism': 1, 'here': 1, 'indicated': 1, 'talent': 1, 'management': 1, 'thing': 1, 'am': 1, 'sure': 1, 'get': 1, 'Half': 1, 'Moon': 1, 'Dartmouth': 1, 'fall': 1, '1609': 1, 'word': 1, \"Hudson's\": 1, 'findings': 1, 'leaked': 1, 'English': 1, 'revived': 1, 'This': 1, 'ignorant': 1, 'estimate': 1, 'repeat': 1, 'itself': 1, 'From': 1, 'Cambridge': 1, 'Palfrey': 1, 'maintained': 1, 'close': 1, 'Neither': 1, 'deaths': 1, 'profited': 1, 'scientific': 1, 'subjects': 1, 'As': 1, 'matter': 1, 'Albert': 1, 'S.': 1, 'Flint': 1, 'conviction': 1, 'physical': 1, 'strength': 1, 'mental': 1, 'lively': 1, 'all': 1, 'objects': 1, 'readiness': 1, 'serve': 1, 'fellow': 1, 'beings': 1, 'distinguished': 1, 'amongst': 1, 'noted': 1, 'women': 1, 'country': 1, 'Vocational': 1, 'holds': 1, 'hope': 1, 'developed': 1, 'marketable': 1, 'chore': 1, 'whose': 1, 'studies': 1, 'begun': 1, 'falter': 1, 'himself': 1, 'owning': 1, 'farm': 1, 'cigar': 1, 'printed': 1, 'round': 1, 'boyish': 1, 'wrappers': 1, 'parade': 1, 'down': 1, 'Fenway': 1, 'Park': 1, 'followed': 1, 'pitchers': 1, 'Carl': 1, 'Mays': 1, 'Leslie': 1, 'Bush': 1, 'Waite': 1, 'Herb': 1, 'Pennock': 1, 'Sam': 1, 'Jones': 1, 'catcher': 1, 'Wally': 1, 'Schang': 1, 'third': 1, 'baseman': 1, 'completed': 1, 'playboy': 1, 'trio': 1, 'shortstop': 1, 'Everett': 1, 'Scott': 1, 'Since': 1, 'attack': 1, 'serves': 1, 'broadcasts': 1, 'my': 1, 'opening': 1, 'statement': 1, 'sentence': 1, 'claimed': 1, 'German': 1, 'youth': 1, 'lack': 1, 'enthusiasm': 1, 'necessary': 1, 'ingredient': 1, 'anger': 1, 'might': 1, 'classified': 1, 'uninterested': 1, 'bored': 1, 'angry': 1, 'All': 1, 'world': 1, 'offered': 1, 'make': 1, 'sacrifices': 1, 'satisfy': 1, 'Most': 1, 'avant-garde': 1, 'creators': 1, 'true': 1, 'self-sufficiency': 1, 'movement': 1, 'tended': 1, 'dress': 1, 'dancers': 1, 'solid': 1, 'colors': 1, 'black': 1, 'bare': 1, 'cyclorama': 1, 'setting': 1, 'painters': 1, 'less': 1, 'moment': 1, 'attendant': 1, 'urgencies': 1, 'ambiguities': 1, 'looking': 1, 'beyond': 1, 'flux': 1, 'particular': 1, 'impressions': 1, 'higher': 1, 'serene': 1, 'level': 1, 'truth': 1, 'My': 1, 'wish': 1, 'meet': 1, 'Beckett': 1, 'prompted': 1, 'curiosity': 1, 'seduced': 1, 'marvels': 1, 'unconscious': 1, 'lost': 1, 'studying': 1, 'surfaces': 1, 'character': 1, 'need': 1, 'protect': 1, 'situations': 1, 'prolonged': 1, 'labor-management': 1, 'stalemate': 1, 'final': 1, 'section': 1, 'pamphlet': 1, 'special': 1, 'consideration': 1, \"Steele's\": 1, 'relations': 1, 'Swift': 1, 'purported': 1, 'reasonably': 1, 'serious': 1, 'musicians': 1, 'aims': 1, 'tug-of-war': 1, 'commercial': 1, 'promising': 1, 'vehicle': 1, 'shared': 1, 'common': 1, 'measures': 1, 'forward': 1, 'regular': 1, 'Democrats': 1, 'young': 1, 'biologist': 1, 'Ballard': 1, 'show': 1, 'Elizabeth': 1, 'induced': 1, 'corresponding': 1, 'reading': 1, 'ranged': 1, 'Agatha': 1, 'Christie': 1, 'Book': 1, 'Of': 1, 'Job': 1, 'insatiable': 1, 'fellow-creatures': 1, 'while': 1, 'full': 1, 'gossip': 1, 'politicians': 1, 'whom': 1, 'intimately': 1, 'thrown': 1, 'six': 1, 'decades': 1, 'before': 1, 'Patchen': 1, 'given': 1, 'evidence': 1, 'musical': 1, 'works': 1, 'Chamber': 1, 'Jazz': 1, 'Sextet': 1, 'ignored': 1, 'critics': 1, 'Each': 1, 'applicant': 1, 'required': 1, 'sufficient': 1, 'property': 1, 'explored': 1, 'Ballet': 1, 'Rhode': 1, 'Island': 1, 'incorporated': 1, 'formed': 1, 'extending': 1, 'knowledge': 1, 'Community': 1, 'performances': 1, 'contribute': 1, 'cultural': 1, 'provide': 1, 'opportunity': 1, 'gifted': 1, 'dance': 1, 'students': 1, 'unable': 1, 'pursue': 1, 'develop': 1, 'professional': 1, 'Between': 1, 'year': 1, 'buying': 1, \"Darling's\": 1, '1892': 1, 'large': 1, 'portion': 1, \"company's\": 1, 'tool': 1, 'carried': 1, 'under': 1, 'name': 1, 'Darling': 1, 'Brown': 1, '&': 1, 'Sharpe': 1, 'day': 1, 'tools': 1, 'bearing': 1, 'famous': 1, 'trademark': 1, 'Club': 1, 'better': 1, 'athletic': 1, 'teams': 1, 'Carleton': 1, 'increase': 1, 'among': 1, 'student': 1, 'body': 1, 'academic': 1, 'dean': 1, 'should': 1, 'direct': 1, 'long-term': 1, 'faculty': 1, 'development': 1, 'That': 1, 'we': 1, 'experiencing': 1, 'upsurge': 1, 'formulations': 1, 'preventive': 1, 'adaptations': 1, 'brief': 1, 'casework': 1, 'evident': 1, 'sampling': 1, 'current': 1, 'literature': 1, 'adherence': 1, 'population': 1, 'Indian': 1, 'background': 1, 'pedigree': 1, 'upon': 1, 'ancestors': 1, 'never': 1, 'prime': 1, 'determining': 1, 'far': 1, 'elements': 1, 'self-image': 1, 'intermediate': 1, 'status': 1, 'did': 1, 'listen': 1, 'ideas': 1, 'right': 1, 'program': 1, 'financial': 1, 'assistance': 1, 'permit': 1, 'placing': 1, 'highly': 1, 'skilled': 1, 'labor': 1, 'Where': 1, \"industry's\": 1, 'product': 1, 'price': 1, 'kept': 1, 'below': 1, 'profit-maximizing': 1, 'entry-limiting': 1, 'prices': 1, 'due': 1, 'fears': 1, 'reaction': 1, 'profit': 1, 'seeking': 1, 'producers': 1, 'offering': 1, 'real': 1, 'resistance': 1, 'wage': 1, 'demands': 1, 'virtually': 1, 'every': 1, 'case': 1, 'transferor': 1, 'corporation': 1, 'liquidated': 1, 'former': 1, 'stockholders': 1, 'outright': 1, 'continuing': 1, 'stock': 1, 'assets': 1, 'gave': 1, 'rise': 1, 'tax': 1, 'questionnaire': 1, 'designed': 1, 'elicit': 1, 'three': 1, 'information': 1, '1': 1, 'facts': 1, 'regarding': 1, 'certain': 1, 'characteristics': 1, 'respondents': 1, 'including': 1, 'securing': 1, 'defense': 1, 'indicate': 1, 'genuine': 1, 'processes': 1, 'events': 1, 'childhood': 1, 'team': 1, 'games': 1, 'replaces': 1, 'individual': 1, 'exhibit': 1, 'keen': 1, 'economic': 1, 'frequently': 1, 'vague': 1, 'incorrect': 1, 'notions': 1, 'terms': 1, 'glibly': 1, 'routine': 1, 'easy': 1, 'rationalize': 1, 'achieving': 1, 'accordance': 1, 'known': 1, 'ability': 1, 'plain': 1, 'lazy': 1, 'lacks': 1, 'dislikes': 1, 'overaggressive': 1, 'hopeless': 1, 'delinquent': 1, 'general': 1, 'appears': 1, 'trustees': 1, 'board': 1, 'represent': 1, 'administration': 1, 'educational': 1, 'policy': 1, 'made': 1, 'easier': 1, 'dominant': 1, 'middle-class': 1, 'generally': 1, 'thought': 1, 'valid': 1, 'entire': 1, \"Manchester's\": 1, 'telegraphy': 1, 'attributed': 1, 'Rev.': 1, 'J.': 1, 'D.': 1, 'Wickham': 1, 'headmaster': 1, 'Burr': 1, 'Burton': 1, 'Seminary': 1, 'friend': 1, 'correspondent': 1, 'inventor': 1, 'F.': 1, 'B.': 1, 'Morse': 1, 'process': 1, 'elimination': 1, 'leaves': 1, 'materials': 1, 'themselves': 1, 'sustain': 1, 'very': 1, 'long': 1, 'Chief': 1, 'radiosterilization': 1, 'resides': 1, 'military': 1, 'services': 1, 'Sandwich': 1, 'panels': 1, 'building': 1, 'utility': 1, 'shelters': 1, 'consist': 1, 'kraft': 1, 'skins': 1, 'rigid': 1, 'styrene': 1, 'foam': 1, 'cores': 1, 'also': 1, 'aroused': 1, 'construction': 1, 'field': 1, 'audience': 1, 'totally': 1, 'engaged': 1, 'witnessing': 1, 'peculiarly': 1, 'fine': 1, 'performance': 1, 'ancient': 1, 'classic': 1, 'guest': 1, 'attentive': 1, 'intelligent': 1, 'does': 1, 'fully': 1, 'understand': 1, 'There': 1, \"hadn't\": 1, 'anything': 1, 'me': 1, 'By': 1, 'Felix': 1, 'turned': 1, 'afternoon': 1, 'think': 1, 'then': 1, 'except': 1, 'children': 1, 'hardy': 1, 'souls': 1, 'sobered': 1, 'could': 1, 'expected': 1, 'having': 1, 'sort': 1, 'active': 1, \"night's\": 1, 'noisemakers': 1, \"It's\": 1, 'too': 1, 'assume': 1, 'lasting': 1, 'Average': 1, 'Citizen': 1, 'going': 1, 'keep': 1, 'scheming': 1, 'poking': 1, 'prodding': 1, 'suggesting': 1, 'dictating': 1, 'until': 1, 'cops': 1, 'got': 1, 'go': 1, 'neighborhood': 1, 'ask': 1, 'drinks': 1, 'complaining': 1, 'bitterly': 1, 'wife': 1, 'subject': 1, 'ten': 1, 'minutes': 1, 'noticed': 1, 'listener': 1, 'alert': 1, 'suddenly': 1, 'bright': 1, 'eyes': 1, 'Reuveni': 1, 'your': 1, 'mother': 1, 'deep': 1, 'refugee': 1})\n"
     ]
    }
   ],
   "source": [
    "print(get_context_around_words(\"interest\",\"in\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 49, ',': 34, 'of': 21, 'to': 20, 'and': 19, 'in': 16, '.': 14, 'will': 11, 'as': 10, 'a': 9, 'that': 8, 'market': 6, 'during': 6, 'which': 5, 'be': 5, 'is': 5, 'for': 5, '1961': 5, 'capital': 5, 'Federal': 5, 'business': 4, 'on': 4, 'It': 4, 'spring': 4, 'may': 4, 'its': 4, '?': 4, '``': 3, \"''\": 3, 'months': 3, 'years': 3, 'run': 3, 'about': 3, 'are': 3, 'with': 3, 'question': 3, 'general': 3, 'monetary': 3, 'policies': 3, 'next': 3, 'long-term': 3, 'lower': 3, 'move': 3, 'rates': 3, 'bonds': 3, 'ease': 3, 'interest': 3, 'forces': 3, 'decline': 3, 'In': 2, 'believe': 2, 'by': 2, 'high': 2, 'has': 2, 'range': 2, 'down': 2, 'Administration': 2, 'activity': 2, 'By': 2, 'demand': 2, 'other': 2, 'several': 2, 'through': 2, 'moderately': 2, 'tend': 2, 'rate': 2, 'mortgage': 2, 'lending': 2, 'residential': 2, 'year': 2, 'terms': 2, 'extent': 2, 'would': 2, 'conduct': 2, 'open': 2, 'operations': 2, 'Government': 2, 'authorities': 2, 'their': 2, 'credit': 2, 'recovery': 2, 'My': 2, 'pertinent': 2, 'ask': 2, ':': 2, 'Has': 2, 'long': 2, 'upswing': 2, 'past': 2, '15': 2, 'just': 2, 'course': 2, 'we': 2, 'now': 2, 'entering': 2, 'period': 2, 'both': 2, 'produce': 2, 'prolonged': 2, 'view': 1, 'current': 1, 'expansion': 1, 'promises': 1, 'substantial': 1, 'he': 1, 'said': 1, 'odds': 1, 'appear': 1, 'favor': 1, 'rising': 1, 'coming': 1, 'but': 1, 'there': 1, 'reason': 1, 'change': 1, 'not': 1, 'abrupt': 1, '1958': 1, 'nor': 1, 'severe': 1, 'late': 1, '1959': 1, '1960': 1, 'Other': 1, 'reasons': 1, 'mentioned': 1, 'one-third': 1, 'or': 1, 'more': 1, 'builders': 1, 'were': 1, 'resistance': 1, 'cost': 1, 'advantage': 1, 'buying': 1, 'over': 1, 'renting': 1, 'narrowed': 1, 'shelter': 1, 'nearing': 1, 'saturation': 1, 'prospects': 1, 'unable': 1, 'qualify': 1, 'Terms': 1, 'from': 1, 'one': 1, 'five': 1, 'payments': 1, 'same': 1, 'automobiles': 1, 'determined': 1, 'board': 1, 'directors': 1, 'bank': 1, 'approval': 1, 'Farm': 1, 'Credit': 1, 'assessing': 1, 'outlook': 1, 'always': 1, 'prospect': 1, 'large': 1, 'what': 1, 'happens': 1, 'whole': 1, 'govern': 1, 'relationship': 1, 'between': 1, 'supply': 1, 'conditions': 1, 'markets': 1, 'thus': 1, 'determine': 1, 'Moreover': 1, 'trend': 1, 'exert': 1, 'decisive': 1, 'influence': 1, 'fiscal': 1, 'affect': 1, 'suggests': 1, 'funds': 1, 'little': 1, 'especially': 1, 'state': 1, 'local': 1, 'well': 1, 'those': 1, 'publicly': 1, 'offered': 1, 'corporate': 1, 'seems': 1, 'likely': 1, 'moreover': 1, 'an': 1, 'increase': 1, 'saving': 1, 'institutions': 1, 'mortgages': 1, 'somewhat': 1, 'although': 1, 'increased': 1, 'occur': 1, 'primarily': 1, 'than': 1, 'e.g.': 1, 'easier': 1, 'downpayment': 1, 'amortization': 1, 'To': 1, 'new': 1, 'wishes': 1, 'Reserve': 1, 'throughout': 1, 'entire': 1, 'maturity': 1, 'securities': 1, 'aggressively': 1, 'seek': 1, 'force': 1, 'However': 1, 'effort': 1, 'longer-term': 1, 'they': 1, 'certainly': 1, 'act': 1, 'accentuate': 1, 'any': 1, 'tendency': 1, 'result': 1, 'end': 1, 'assuming': 1, 'gets': 1, 'under': 1, 'way': 1, 'should': 1, 'begin': 1, 'edge': 1, 'upward': 1, 'again': 1, 'depending': 1, 'upon': 1, 'vigor': 1, 'determination': 1, 'restrain': 1, 'availability': 1, 'guess': 1, 'into': 1, 'second': 1, 'half': 1, 'turn': 1, 'up': 1, 'gradually': 1, 'recover': 1, 'ground': 1, 'lost': 1, 'downturn': 1, 'answer': 1, 'negative': 1, 'because': 1, 'I': 1, 'total': 1, 'demands': 1, 'Sixties': 1, 'continue': 1, 'press': 1, 'against': 1, 'available': 1, 'supplies': 1, 'generally': 1, 'firm': 1, 'at': 1, 'levels': 1})\n"
     ]
    }
   ],
   "source": [
    "print(get_context_around_words(\"interest\",\"rates\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use this to find other (nearly) unambiguous cases, collecting enough of examples of each that we could build a classifer to deal with more borderline cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For very distinct senses, it is possible to cluster different senses of a words given only a large corpus, an unsupervised task. This is known as Word Sense Induction.\n",
    "\n",
    "Note that like most unsupervised tasks, this would not label the classes for us - an expert would need to investigate the clusters and determine \"these words are \"news words\", these ones are \"sports\" words, etc.\".\n",
    "\n",
    "**And here is the reality of all machine learning tasks: they require some manual work at some point.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Content Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Content analysis is a methodology used primarily in Social Sciences for studying text documents. Typically, it is little more than counting using a large, hand-built lexicon where each word is tagged for various different properties. The [General Inquirer](http://www.wjh.harvard.edu/~inquirer/) is a classic example of this, and is publicly available. Let's use it to do a simple content analysis of individual genres of the Brown corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (63,108,109,110,176) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"inquireraugmented.tsv\",sep=\"\\t\")\n",
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entry</th>\n",
       "      <th>Source</th>\n",
       "      <th>Positiv</th>\n",
       "      <th>Negativ</th>\n",
       "      <th>Pstv</th>\n",
       "      <th>Affil</th>\n",
       "      <th>Ngtv</th>\n",
       "      <th>Hostile</th>\n",
       "      <th>Strong</th>\n",
       "      <th>Power</th>\n",
       "      <th>...</th>\n",
       "      <th>Anomie</th>\n",
       "      <th>NegAff</th>\n",
       "      <th>PosAff</th>\n",
       "      <th>SureLw</th>\n",
       "      <th>If</th>\n",
       "      <th>NotLw</th>\n",
       "      <th>TimeSpc</th>\n",
       "      <th>FormLw</th>\n",
       "      <th>Othrtags</th>\n",
       "      <th>Defined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1915</td>\n",
       "      <td>2291</td>\n",
       "      <td>1045</td>\n",
       "      <td>557</td>\n",
       "      <td>1160</td>\n",
       "      <td>833</td>\n",
       "      <td>1902</td>\n",
       "      <td>689</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>193</td>\n",
       "      <td>126</td>\n",
       "      <td>175</td>\n",
       "      <td>132</td>\n",
       "      <td>25</td>\n",
       "      <td>428</td>\n",
       "      <td>368</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>DET ART</td>\n",
       "      <td>| article: Indefinite singular article--some o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABANDON</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td></td>\n",
       "      <td>Negativ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Ngtv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABANDONMENT</td>\n",
       "      <td>H4</td>\n",
       "      <td></td>\n",
       "      <td>Negativ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABATE</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td></td>\n",
       "      <td>Negativ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABATEMENT</td>\n",
       "      <td>Lvd</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABDICATE</td>\n",
       "      <td>H4</td>\n",
       "      <td></td>\n",
       "      <td>Negativ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ABHOR</td>\n",
       "      <td>H4</td>\n",
       "      <td></td>\n",
       "      <td>Negativ</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Hostile</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ABIDE</td>\n",
       "      <td>H4</td>\n",
       "      <td>Positiv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Affil</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>SUPV</td>\n",
       "      <td>|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ABILITY</td>\n",
       "      <td>H4Lvd</td>\n",
       "      <td>Positiv</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Strong</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Noun</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 186 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Entry Source  Positiv  Negativ  Pstv  Affil  Ngtv  Hostile  Strong  \\\n",
       "0                         1915     2291  1045    557  1160      833    1902   \n",
       "1            A  H4Lvd                                                         \n",
       "2      ABANDON  H4Lvd           Negativ               Ngtv                    \n",
       "3  ABANDONMENT     H4           Negativ                                       \n",
       "4        ABATE  H4Lvd           Negativ                                       \n",
       "5    ABATEMENT    Lvd                                                         \n",
       "6     ABDICATE     H4           Negativ                                       \n",
       "7        ABHOR     H4           Negativ                     Hostile           \n",
       "8        ABIDE     H4  Positiv                 Affil                          \n",
       "9      ABILITY  H4Lvd  Positiv                                       Strong   \n",
       "\n",
       "  Power  ... Anomie NegAff PosAff SureLw   If NotLw TimeSpc FormLw Othrtags  \\\n",
       "0   689  ...     30    193    126    175  132    25     428    368            \n",
       "1        ...                                                        DET ART   \n",
       "2        ...                                                           SUPV   \n",
       "3        ...                                                           Noun   \n",
       "4        ...                                                           SUPV   \n",
       "5        ...                                                           Noun   \n",
       "6        ...                                                           SUPV   \n",
       "7        ...                                                           SUPV   \n",
       "8        ...                                                           SUPV   \n",
       "9        ...                                                           Noun   \n",
       "\n",
       "                                             Defined  \n",
       "0                                                     \n",
       "1  | article: Indefinite singular article--some o...  \n",
       "2                                                  |  \n",
       "3                                                  |  \n",
       "4                                                  |  \n",
       "5                                                     \n",
       "6                                                  |  \n",
       "7                                                  |  \n",
       "8                                                  |  \n",
       "9                                                     \n",
       "\n",
       "[10 rows x 186 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's take a close look at the different features the words can have. There is an explanation of these features [here](http://www.wjh.harvard.edu/~inquirer/homecat.htm), note that there are some reduncancies because the GI is actually an amalgamation of earlier separate lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Entry', 'Source', 'Positiv', 'Negativ', 'Pstv', 'Affil', 'Ngtv', 'Hostile', 'Strong', 'Power', 'Weak', 'Submit', 'Active', 'Passive', 'Pleasur', 'Pain', 'Feel', 'Arousal', 'EMOT', 'Virtue', 'Vice', 'Ovrst', 'Undrst', 'Academ', 'Doctrin', 'Econ@', 'Exch', 'ECON', 'Exprsv', 'Legal', 'Milit', 'Polit@', 'POLIT', 'Relig', 'Role', 'COLL', 'Work', 'Ritual', 'SocRel', 'Race', 'Kin@', 'MALE', 'Female', 'Nonadlt', 'HU', 'ANI', 'PLACE', 'Social', 'Region', 'Route', 'Aquatic', 'Land', 'Sky', 'Object', 'Tool', 'Food', 'Vehicle', 'BldgPt', 'ComnObj', 'NatObj', 'BodyPt', 'ComForm', 'COM', 'Say', 'Need', 'Goal', 'Try', 'Means', 'Persist', 'Complet', 'Fail', 'NatrPro', 'Begin', 'Vary', 'Increas', 'Decreas', 'Finish', 'Stay', 'Rise', 'Exert', 'Fetch', 'Travel', 'Fall', 'Think', 'Know', 'Causal', 'Ought', 'Perceiv', 'Compare', 'Eval@', 'EVAL', 'Solve', 'Abs@', 'ABS', 'Quality', 'Quan', 'NUMB', 'ORD', 'CARD', 'FREQ', 'DIST', 'Time@', 'TIME', 'Space', 'POS', 'DIM', 'Rel', 'COLOR', 'Self', 'Our', 'You', 'Name', 'Yes', 'No', 'Negate', 'Intrj', 'IAV', 'DAV', 'SV', 'IPadj', 'IndAdj', 'PowGain', 'PowLoss', 'PowEnds', 'PowAren', 'PowCon', 'PowCoop', 'PowAuPt', 'PowPt', 'PowDoct', 'PowAuth', 'PowOth', 'PowTot', 'RcEthic', 'RcRelig', 'RcGain', 'RcLoss', 'RcEnds', 'RcTot', 'RspGain', 'RspLoss', 'RspOth', 'RspTot', 'AffGain', 'AffLoss', 'AffPt', 'AffOth', 'AffTot', 'WltPt', 'WltTran', 'WltOth', 'WltTot', 'WlbGain', 'WlbLoss', 'WlbPhys', 'WlbPsyc', 'WlbPt', 'WlbTot', 'EnlGain', 'EnlLoss', 'EnlEnds', 'EnlPt', 'EnlOth', 'EnlTot', 'SklAsth', 'SklPt', 'SklOth', 'SklTOT', 'TrnGain', 'TrnLoss', 'TranLw', 'MeansLw', 'EndsLw', 'ArenaLw', 'PtLw', 'Nation', 'Anomie', 'NegAff', 'PosAff', 'SureLw', 'If', 'NotLw', 'TimeSpc', 'FormLw', 'Othrtags', 'Defined']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's convert this to something a bit easier to work with (and look at), a Python dictionary which contains a set of applicable categories for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: in a `csv.reader()`, you get the output like this where each line is a row:\n",
    "['Entry', ..., 'SklAsth', 'SklPt', 'SklOth', 'SklTOT', 'TrnGain', 'TrnLoss', 'TranLw', 'MeansLw', 'EndsLw', 'ArenaLw', 'PtLw', 'Nation', 'Anomie', 'NegAff', 'PosAff', 'SureLw', 'If', 'NotLw', 'TimeSpc', 'FormLw', 'Othrtags', 'Defined'],\n",
    "['', '', '1915', '2291', ... '368', '', ''],\n",
    "['A', 'H4Lvd', ..., 'DET ART', '| article: Indefinite singular article--some or any one']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "GI_lexicon = defaultdict(set)\n",
    "\n",
    "f = open(\"inquireraugmented.tsv\")\n",
    "reader = csv.reader(f,delimiter='\\t')\n",
    "for line in reader:\n",
    "    word = line[0].split(\"#\")[0].lower()\n",
    "    for i in range(2,184):\n",
    "        if line[i].strip():\n",
    "            GI_lexicon[word].add(line[i])\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HU', 'POLIT', 'Polit@', 'PowAuPt', 'PowTot', 'Power', 'Role', 'Strong'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GI_lexicon[\"politician\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EMOT', 'Pleasur', 'PosAff', 'Positiv', 'Pstv', 'WlbPsyc', 'WlbTot'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GI_lexicon[\"happy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EMOT', 'Negativ', 'Ngtv', 'Pain', 'Passive', 'WlbPsyc', 'WlbTot'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GI_lexicon[\"sad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Next, we need a function that counts all the categories for a particular corpus (list of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_GI_counts(words):\n",
    "    '''return a dictionary of counts of occurrence of each GI lexicon\n",
    "    in a list of words, and the total number of words'''\n",
    "    counts = Counter()\n",
    "    total_words = 0\n",
    "    for word in words:\n",
    "        total_words += 1\n",
    "        word = word.lower()\n",
    "        counts.update(GI_lexicon.get(word,[]))  # if word is not in the set, return []\n",
    "    return counts,total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can compare individual features across corpora by normalizing the counts. Let's look at features like \"EMOT\" and \"POLIT\" which should show a preference for one genre or the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "fict_counts,fict_total = get_GI_counts(brown.words(categories=\"fiction\"))\n",
    "gov_counts,gov_total = get_GI_counts(brown.words(categories=\"government\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010264571895806564"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fict_counts[\"EMOT\"]/fict_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004121682330961108"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gov_counts[\"EMOT\"]/gov_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017930148347155707"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fict_counts[\"POLIT\"]/fict_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05175635010054623"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gov_counts[\"POLIT\"]/gov_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "These look fairly distinct, but how do we know whether the differences we are seeing actually mean something? Statistical testing! Let's use the counts directly in a [$\\chi^2$ test](https://en.wikipedia.org/wiki/Chi-squared_test). \n",
    "\n",
    "Just for review, the $\\chi^2$ test can be used to test whether it is likely that the same underlying statistical process generated two or more categories of count data. It is one of the most useful statistical tests for computational linguistics applications! To use it we simply need to construct a contingency table of the following form:\n",
    "\n",
    "| Count type           | Document set 1 | Document set 2 |\n",
    "|----------------------|----------------|----------------|\n",
    "| tokens in lexicon     |     1228         |      3629        | \n",
    "| tokens not in lexicon |     67260     |       66488         |\n",
    "\n",
    "Let's fill out this table manually using an example from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fict_counts[\"POLIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67260"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fict_total - fict_counts[\"POLIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3629"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gov_counts[\"POLIT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66488"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gov_total - gov_counts[\"POLIT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a lexical count and a total for two categories, we can use scipy's [chi2_contingency](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html) to call the function below to construct the table and get a p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def get_p_value(count1,total1,count2,total2):\n",
    "    return chi2_contingency([[count1, count2],[total1-count1,total2-count2]])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0131730384029113e-256"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_p_value(fict_counts[\"POLIT\"],fict_total,gov_counts[\"POLIT\"],gov_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7019248198799348e-14"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_p_value(50, 100, 2, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, that is statistically significant! $\\chi^2$ doesn't tell us anything about the directionality of the relation, we would need to look at the original ratios for that.\n",
    "\n",
    "Finally, let's go searching for low p-value lexical classes. Note that we when do many tests like this, we should apply the [Bonferroni](https://en.wikipedia.org/wiki/Bonferroni_correction) or something similar, the normal p < 0.05 cutoff for statistical significance is no longer valid. This won't usually be a problem, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highest_ps(counts1,counts2,total1,total2):\n",
    "    '''given lexicon counts for two document collections, print the top \n",
    "    25 lexicons for distinguishing the two collections in terms of their \n",
    "    chi-square p-value'''\n",
    "    to_sort = []\n",
    "    all_features = set(counts1)\n",
    "    all_features.update(counts2)\n",
    "    for feature in all_features:\n",
    "        to_sort.append((get_p_value(counts1.get(feature,0),total1,counts2.get(feature,0), total2),feature))\n",
    "    to_sort.sort()\n",
    "    print(to_sort[:25])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 'ECON'), (0.0, 'MALE'), (1.0131730384029113e-256, 'POLIT'), (1.0899851560042814e-230, 'Female'), (8.215329763085285e-186, 'WltTot'), (8.559042732884123e-177, 'Econ@'), (3.325303663333495e-170, 'Doctrin'), (3.2405878752386136e-156, 'WltOth'), (1.6231680491880572e-154, 'PowTot'), (1.295343865383213e-107, 'Self'), (2.490830178891491e-103, 'Strong'), (5.517322897976327e-96, 'ABS'), (1.2530683111938407e-92, 'COLL'), (1.8444080804326904e-88, 'BodyPt'), (1.37755034301735e-70, 'Abs@'), (3.475313128766613e-70, 'DAV'), (5.554324680658735e-69, 'PowOth'), (1.52434986952163e-66, 'EndsLw'), (1.5864221396139325e-63, 'Know'), (5.757380211858323e-62, 'Means'), (3.1548427300660787e-60, 'Polit@'), (4.6389068590393685e-60, 'PowAuPt'), (1.542283985697429e-59, 'Intrj'), (4.493380189728371e-56, 'Virtue'), (1.4062380296799672e-52, 'Say')]\n"
     ]
    }
   ],
   "source": [
    "find_highest_ps(fict_counts,gov_counts,fict_total,gov_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04304403691157575"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fict_counts[\"MALE\"]/fict_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00740191394383673"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gov_counts[\"MALE\"]/gov_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A more modern, more popular lexicon for content analysis is the [Linguistic Inquiry and Word Count (LIWC, pronounced Luke)](http://liwc.wpengine.com/). LIWC is a commercial product and so we won't be distributing it. If you are serious about content analysis, LIWC is the gold standard among general, off-the-shelf approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's pick another pair of Brown genres, investigate what GI lexical features distinguish them, and come up with a rationale as to why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 'Relig'), (3.85823625266287e-233, 'RcTot'), (6.079184235101566e-213, 'RcRelig'), (7.076536193882808e-94, 'PowAuPt'), (3.9375763748424565e-93, 'Our'), (1.4683528136143864e-92, 'RcEnds'), (1.150379509654069e-65, 'ECON'), (2.257597059311751e-65, 'PowTot'), (4.6061510497257784e-63, 'Econ@'), (3.117469298855974e-62, 'POLIT'), (8.908051704090205e-60, 'Ovrst'), (5.291024512891382e-59, 'Abs@'), (8.043785847291017e-54, 'You'), (3.2851729794897512e-49, 'WltTot'), (2.622544286528954e-48, 'Know'), (2.5573863934419464e-45, 'Polit@'), (4.8540712883023225e-43, 'Passive'), (7.864775080281807e-38, 'Female'), (3.2282757638165437e-36, 'Virtue'), (2.5010186185960975e-35, 'NotLw'), (8.542651243659839e-35, 'WltOth'), (7.824272680956149e-34, 'Intrj'), (1.2648804358134442e-33, 'NatrPro'), (5.740638841422914e-33, 'Negate'), (8.505449903030259e-32, 'Undrst')]\n"
     ]
    }
   ],
   "source": [
    "news_counts, news_total = get_GI_counts(brown.words(categories=\"news\"))\n",
    "religion_counts, religion_total = get_GI_counts(brown.words(categories=\"religion\"))\n",
    "\n",
    "find_highest_ps(news_counts,religion_counts, news_total,religion_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023340692563199872"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_counts[\"Virtue\"]/news_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03540699002512754"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religion_counts[\"Virtue\"]/religion_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review:\n",
    "\n",
    "1. WordNet is a network of *synsets*, not words.\n",
    "2. Each synset in WordNet is associated with one or more lemmas.\n",
    "3. \"I stopped at the bank before shopping\" and \"my bank account is empty\" involves two different senses of the word \"bank\".\n",
    "4. To calculate Wupalmer distance you need to identify the lowest common subsumer of two synsets you want to calcuate the distance for.\n",
    "5. Foot is not a hyponym of leg, but a *meronym* of leg.(because foot is a part of leg)\n",
    "6. Word sense disambiguation is a important problem in natural language understanding. \n",
    "7. If a word has two senses, one of which appear 8 times, the other which appears 2 times, the most frequent sense baseline is 0.8.\n",
    "8. The Lesk algorithm involves comparing the definition of each sense with the context around the occurrence of the word.\n",
    "9. To use $\\chi^2$ in the context of content analysis, we need to have counts for two different lexicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
