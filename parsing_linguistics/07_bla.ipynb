{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical lecture 7: Dependency parsing\n",
    "\n",
    "## 1. Converting tabular format to NLTK DependencyDraph format\n",
    "\n",
    "Let's start by importing the NLTK data structure for dependency trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import DependencyGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's then build a tabular parse tree for the sentence \"I saw the cat\". The NLTK tabular format consists of four columns:\n",
    "\n",
    "1. word form\n",
    "1. POS tag\n",
    "1. ID of head word (the syntactic head of the sentence has head ID 0)\n",
    "1. Dependency relation\n",
    "\n",
    "Both the POS tag and dependency relation need to be written in uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree='''I   PRON   2   NSUBJ\n",
    "saw   VERB   0   ROOT\n",
    "the   DET    4   DET\n",
    "cat   NOUN   2   OBJ\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then convert this to a `DependencyGraph`. These dependency graphs give you a logical format for the sentence `(HEAD DEP1 ... DEPN)`, where head is the head word of a construction and `DEP1`, ..., `DEPN` are its dependents. These may then in turn have their own dependents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = DependencyGraph(tree)\n",
    "print(dg.tree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using dependency treebanks\n",
    "\n",
    "NLTK offers a large dependency annotated treebank which has been automatically converted from the Penn Treebank. This treebank **is not** in UD format but can still be useful if we want to train dependency parsers.\n",
    "\n",
    "Let's start by downloading the treebank:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download(\"dependency_treebank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the first sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import dependency_treebank\n",
    "\n",
    "print(dependency_treebank.sents()[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then print the dependency tree for the first sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dependency_treebank.parsed_sents()[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access individual tokens by their ID number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph.get_by_address(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also gives us access to the children in the tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for address in graph.get_by_address(2)['deps']['']:\n",
    "    print(graph.get_by_address(address))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dependency parsing using SpaCy\n",
    "\n",
    "NLTK doesn't really provide a good dependency parser that we could apply on our own sentences but we can get one from the SpaCy toolkit. \n",
    "\n",
    "You should start by running the commands:\n",
    "```\n",
    "pip3 install spacy\n",
    "python3 -m spacy download en_core_web_sm\n",
    "```\n",
    "in the terminal.\n",
    "\n",
    "We can now use SpaCy to dependency parse some input sentences. \n",
    "\n",
    "**Note!** The output is in UD 1.0 format, not UD 2.0 which we saw in the lecture. This means that some relations look a bit different. For example, we've got \"dobj\" for direct objects instead of \"obj\" which we saw in the lecture.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "sentence = \"foxes like cats but they don't really like dogs\"\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sent = nlp(sentence)\n",
    "for token in sent:\n",
    "    print(((token,token.i),(token.head, token.head.i),token.dep_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize parse trees using SpaCy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(sent, style=\"dep\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Assignment: dependency parsing using SpaCy\n",
    "\n",
    "Following the example above, parse the sentence \"The gray cat meowed\" using SpaCy and print the parse tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualize the dependency tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Assignment: Tree conversion\n",
    "\n",
    "Write a function `spacy_to_dict` which converts your SpaCy dependency tree into a disctionary, where the keys are the ID numbers for the words in your sentence and the values are sets of child IDs. You should add a root element with ID 0 whose child is the syntactic head of the entire sentence. \n",
    "\n",
    "You should be able to build the function using the following properties of SpaCy trees:\n",
    "\n",
    "1. You can access the children of a token in a SpaCy tree using `token.children`.\n",
    "1. For any token token.i will give you its ID number (this also applies to child tokens in `token.children`). Note! SpaCy trees do not have a separate `ROOT` element and indexing for regular word forms starts at 0. You will, therefore, need to add one to your indices. \n",
    "1. Unlike NLKT dependency trees, SpaCy trees mark the syntactic head of the entire sentence as a word that is its own head.\n",
    "\n",
    "For example, the output of `spacy_to_dict` for `sent` should be:\n",
    "\n",
    "```\n",
    "{0:set([4]), 1:set(), 2:set(), 3:set([1,2]), 4:set([3])}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
